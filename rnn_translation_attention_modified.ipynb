{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "\n",
    "#################### Ignore from this part to ####################\n",
    "\n",
    "# Download the file\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\"\n",
    "\n",
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "  w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "  # creating a space between a word and the punctuation following it\n",
    "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "  w = w.strip()\n",
    "\n",
    "  # adding a start and an end token to the sentence\n",
    "  # so that the model know when to start and stop predicting.\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w\n",
    "\n",
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
    "def create_dataset(path, num_examples):\n",
    "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "\n",
    "  return zip(*word_pairs)\n",
    "\n",
    "en, sp = create_dataset(path_to_file, None)\n",
    "\n",
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "  return tensor, lang_tokenizer\n",
    "\n",
    "def load_dataset(path, num_examples=None):\n",
    "    # クリーニングされた入力と出力のペアを生成\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "    \n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\n",
    "\n",
    "# このサイズのデータセットで実験\n",
    "num_examples = 30000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# ターゲットテンソルの最大長を計算\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
    "\n",
    "# 80-20で分割を行い、訓練用と検証用のデータセットを作成\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))\n",
    "\n",
    "#################### this part. ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24000, 16), (6000, 16), (24000, 11), (6000, 11))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_train.shape, input_tensor_val.shape, target_tensor_train.shape, target_tensor_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,  715,   10, ...,    0,    0,    0],\n",
       "       [   1,   39, 2934, ...,    0,    0,    0],\n",
       "       [   1,    9,    8, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   1,    6,   11, ...,    0,    0,    0],\n",
       "       [   1,    8,  312, ...,    0,    0,    0],\n",
       "       [   1,    4,   91, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1, 715,  10, 164,   3,   2,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ----> <start>\n",
      "715 ----> limitate\n",
      "10 ----> a\n",
      "164 ----> hacerlo\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "convert(inp_lang, input_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside tokenize()\n",
      "\n",
      "('<', 's', 't', 'a', 'r', 't', '>', ' ', 'm', 'a', 'd', 'r', 'e', ' ', '.', ' ', '<', 'e', 'n', 'd', '>')\n"
     ]
    }
   ],
   "source": [
    "a=tokenize(tuple('<start> madre . <end>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1],\n",
       "        [ 8],\n",
       "        [ 2],\n",
       "        [ 3],\n",
       "        [ 4],\n",
       "        [ 2],\n",
       "        [ 5],\n",
       "        [ 0],\n",
       "        [ 9],\n",
       "        [ 3],\n",
       "        [ 6],\n",
       "        [ 4],\n",
       "        [ 7],\n",
       "        [ 0],\n",
       "        [10],\n",
       "        [ 0],\n",
       "        [ 1],\n",
       "        [ 7],\n",
       "        [11],\n",
       "        [ 6],\n",
       "        [ 5]], dtype=int32),\n",
       " <keras_preprocessing.text.Tokenizer at 0x7f8250162d10>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,  135,    3, ...,    0,    0,    0],\n",
       "       [   1,  293,    3, ...,    0,    0,    0],\n",
       "       [   1,  595,    3, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   1,   18, 9413, ...,    0,    0,    0],\n",
       "       [   1,   63, 2490, ...,    0,    0,    0],\n",
       "       [   1,   23, 2175, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,  81, 118,   3,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9413"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inp_lang.word_index.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000 24000 6000 6000\n"
     ]
    }
   ],
   "source": [
    "# 80-20で分割を行い、訓練用と検証用のデータセットを作成\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# 長さを表示\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 16)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    4,   17,   16, 2258,   27,    2,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 11)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<start> go . <end>',\n",
       " '<start> go . <end>',\n",
       " '<start> go . <end>',\n",
       " '<start> go . <end>',\n",
       " '<start> hi . <end>',\n",
       " '<start> run ! <end>',\n",
       " '<start> run . <end>',\n",
       " '<start> who ? <end>',\n",
       " '<start> fire ! <end>',\n",
       " '<start> fire ! <end>',\n",
       " '<start> fire ! <end>',\n",
       " '<start> help ! <end>',\n",
       " '<start> help ! <end>',\n",
       " '<start> help ! <end>',\n",
       " '<start> jump ! <end>',\n",
       " '<start> jump . <end>',\n",
       " '<start> stop ! <end>',\n",
       " '<start> stop ! <end>',\n",
       " '<start> stop ! <end>',\n",
       " '<start> wait ! <end>',\n",
       " '<start> wait . <end>',\n",
       " '<start> go on . <end>',\n",
       " '<start> go on . <end>',\n",
       " '<start> hello ! <end>',\n",
       " '<start> i ran . <end>',\n",
       " '<start> i ran . <end>',\n",
       " '<start> i try . <end>',\n",
       " '<start> i won ! <end>',\n",
       " '<start> oh no ! <end>',\n",
       " '<start> relax . <end>',\n",
       " '<start> smile . <end>',\n",
       " '<start> attack ! <end>',\n",
       " '<start> attack ! <end>',\n",
       " '<start> get up . <end>',\n",
       " '<start> go now . <end>',\n",
       " '<start> got it ! <end>',\n",
       " '<start> got it ? <end>',\n",
       " '<start> got it ? <end>',\n",
       " '<start> he ran . <end>',\n",
       " '<start> hop in . <end>',\n",
       " '<start> hug me . <end>',\n",
       " '<start> i fell . <end>',\n",
       " '<start> i know . <end>',\n",
       " '<start> i left . <end>',\n",
       " '<start> i lied . <end>',\n",
       " '<start> i lost . <end>',\n",
       " '<start> i quit . <end>',\n",
       " '<start> i quit . <end>',\n",
       " '<start> i work . <end>',\n",
       " '<start> i m . <end>',\n",
       " '<start> i m up . <end>',\n",
       " '<start> listen . <end>',\n",
       " '<start> listen . <end>',\n",
       " '<start> listen . <end>',\n",
       " '<start> no way ! <end>',\n",
       " '<start> no way ! <end>',\n",
       " '<start> no way ! <end>',\n",
       " '<start> no way ! <end>',\n",
       " '<start> no way ! <end>',\n",
       " '<start> no way ! <end>',\n",
       " '<start> no way ! <end>',\n",
       " '<start> no way ! <end>',\n",
       " '<start> no way ! <end>',\n",
       " '<start> no way ! <end>',\n",
       " '<start> really ? <end>',\n",
       " '<start> really ? <end>',\n",
       " '<start> thanks . <end>',\n",
       " '<start> thanks . <end>',\n",
       " '<start> try it . <end>',\n",
       " '<start> we try . <end>',\n",
       " '<start> we won . <end>',\n",
       " '<start> why me ? <end>',\n",
       " '<start> ask tom . <end>',\n",
       " '<start> awesome ! <end>',\n",
       " '<start> be calm . <end>',\n",
       " '<start> be cool . <end>',\n",
       " '<start> be fair . <end>',\n",
       " '<start> be kind . <end>',\n",
       " '<start> be nice . <end>',\n",
       " '<start> beat it . <end>',\n",
       " '<start> call me . <end>',\n",
       " '<start> call me . <end>',\n",
       " '<start> call me . <end>',\n",
       " '<start> call us . <end>',\n",
       " '<start> come in . <end>',\n",
       " '<start> come in . <end>',\n",
       " '<start> come in . <end>',\n",
       " '<start> come on ! <end>',\n",
       " '<start> come on . <end>',\n",
       " '<start> come on . <end>',\n",
       " '<start> drop it ! <end>',\n",
       " '<start> get tom . <end>',\n",
       " '<start> get out ! <end>',\n",
       " '<start> get out . <end>',\n",
       " '<start> get out . <end>',\n",
       " '<start> get out . <end>',\n",
       " '<start> get out . <end>',\n",
       " '<start> get out . <end>',\n",
       " '<start> go away ! <end>',\n",
       " '<start> go away ! <end>',\n",
       " '<start> go away ! <end>',\n",
       " '<start> go away ! <end>',\n",
       " '<start> go away ! <end>',\n",
       " '<start> go away ! <end>',\n",
       " '<start> go away ! <end>',\n",
       " '<start> go away . <end>',\n",
       " '<start> go away . <end>',\n",
       " '<start> go away . <end>',\n",
       " '<start> go away . <end>',\n",
       " '<start> go away . <end>',\n",
       " '<start> go away . <end>',\n",
       " '<start> go away . <end>',\n",
       " '<start> go home . <end>',\n",
       " '<start> go slow . <end>',\n",
       " '<start> goodbye ! <end>',\n",
       " '<start> goodbye ! <end>',\n",
       " '<start> goodbye ! <end>',\n",
       " '<start> hang on ! <end>',\n",
       " '<start> hang on ! <end>',\n",
       " '<start> hang on ! <end>',\n",
       " '<start> hang on . <end>',\n",
       " '<start> he came . <end>',\n",
       " '<start> he quit . <end>',\n",
       " '<start> help me ! <end>',\n",
       " '<start> help me . <end>',\n",
       " '<start> help me . <end>',\n",
       " '<start> help me . <end>',\n",
       " '<start> help us . <end>',\n",
       " '<start> hit tom . <end>',\n",
       " '<start> hold it ! <end>',\n",
       " '<start> hold on . <end>',\n",
       " '<start> hold on . <end>',\n",
       " '<start> hold on . <end>',\n",
       " '<start> hug tom . <end>',\n",
       " '<start> i agree . <end>',\n",
       " '<start> i agree . <end>',\n",
       " '<start> i bowed . <end>',\n",
       " '<start> i moved . <end>',\n",
       " '<start> i moved . <end>',\n",
       " '<start> i moved . <end>',\n",
       " '<start> i moved . <end>',\n",
       " '<start> i slept . <end>',\n",
       " '<start> i tried . <end>',\n",
       " '<start> i ll go . <end>',\n",
       " '<start> i m tom . <end>',\n",
       " '<start> i m fat . <end>',\n",
       " '<start> i m fat . <end>',\n",
       " '<start> i m fit . <end>',\n",
       " '<start> i m hit ! <end>',\n",
       " '<start> i m old . <end>',\n",
       " '<start> i m shy . <end>',\n",
       " '<start> i m wet . <end>',\n",
       " '<start> it s ok . <end>',\n",
       " '<start> it s me ! <end>',\n",
       " '<start> it s me . <end>',\n",
       " '<start> join us . <end>',\n",
       " '<start> join us . <end>',\n",
       " '<start> keep it . <end>',\n",
       " '<start> me , too . <end>',\n",
       " '<start> open up . <end>',\n",
       " '<start> perfect ! <end>',\n",
       " '<start> see you . <end>',\n",
       " '<start> show me . <end>',\n",
       " '<start> show me . <end>',\n",
       " '<start> show me . <end>',\n",
       " '<start> shut up ! <end>',\n",
       " '<start> shut up ! <end>',\n",
       " '<start> skip it . <end>',\n",
       " '<start> so long . <end>',\n",
       " '<start> so long . <end>',\n",
       " '<start> stop it . <end>',\n",
       " '<start> stop it . <end>',\n",
       " '<start> take it . <end>',\n",
       " '<start> tell me . <end>',\n",
       " '<start> tom ate . <end>',\n",
       " '<start> tom ran . <end>',\n",
       " '<start> tom won . <end>',\n",
       " '<start> wait up . <end>',\n",
       " '<start> wake up ! <end>',\n",
       " '<start> wake up ! <end>',\n",
       " '<start> wake up ! <end>',\n",
       " '<start> wake up . <end>',\n",
       " '<start> wash up . <end>',\n",
       " '<start> we care . <end>',\n",
       " '<start> we know . <end>',\n",
       " '<start> we lost . <end>',\n",
       " '<start> welcome . <end>',\n",
       " '<start> welcome . <end>',\n",
       " '<start> who ate ? <end>',\n",
       " '<start> who ran ? <end>',\n",
       " '<start> who ran ? <end>',\n",
       " '<start> who won ? <end>',\n",
       " '<start> who won ? <end>',\n",
       " '<start> why not ? <end>',\n",
       " '<start> you run . <end>',\n",
       " '<start> you won . <end>',\n",
       " '<start> am i fat ? <end>',\n",
       " '<start> ask them . <end>',\n",
       " '<start> ask them . <end>',\n",
       " '<start> back off ! <end>',\n",
       " '<start> back off . <end>',\n",
       " '<start> be a man . <end>',\n",
       " '<start> be brave . <end>',\n",
       " '<start> be brief . <end>',\n",
       " '<start> be brief . <end>',\n",
       " '<start> be brief . <end>',\n",
       " '<start> be quiet . <end>',\n",
       " '<start> be still . <end>',\n",
       " '<start> call tom . <end>',\n",
       " '<start> call tom . <end>',\n",
       " '<start> call tom . <end>',\n",
       " '<start> cheer up ! <end>',\n",
       " '<start> cheer up . <end>',\n",
       " '<start> cool off ! <end>',\n",
       " '<start> cuff him . <end>',\n",
       " '<start> don t go . <end>',\n",
       " '<start> drive on . <end>',\n",
       " '<start> find tom . <end>',\n",
       " '<start> find tom . <end>',\n",
       " '<start> find tom . <end>',\n",
       " '<start> find tom . <end>',\n",
       " '<start> find tom . <end>',\n",
       " '<start> find tom . <end>',\n",
       " '<start> fix this . <end>',\n",
       " '<start> get away ! <end>',\n",
       " '<start> get away ! <end>',\n",
       " '<start> get away ! <end>',\n",
       " '<start> get away ! <end>',\n",
       " '<start> get down ! <end>',\n",
       " '<start> get down . <end>',\n",
       " '<start> get down . <end>',\n",
       " '<start> get lost ! <end>',\n",
       " '<start> get lost ! <end>',\n",
       " '<start> get lost ! <end>',\n",
       " '<start> get lost ! <end>',\n",
       " '<start> get lost ! <end>',\n",
       " '<start> get lost . <end>',\n",
       " '<start> get real ! <end>',\n",
       " '<start> get real ! <end>',\n",
       " '<start> get real . <end>',\n",
       " '<start> go ahead ! <end>',\n",
       " '<start> go ahead . <end>',\n",
       " '<start> go on in . <end>',\n",
       " '<start> go on in . <end>',\n",
       " '<start> go on in . <end>',\n",
       " '<start> go on in . <end>',\n",
       " '<start> go on in . <end>',\n",
       " '<start> good job ! <end>',\n",
       " '<start> grab tom . <end>',\n",
       " '<start> grab him . <end>',\n",
       " '<start> have fun . <end>',\n",
       " '<start> have fun . <end>',\n",
       " '<start> have fun . <end>',\n",
       " '<start> he spoke . <end>',\n",
       " '<start> he tries . <end>',\n",
       " '<start> he tries . <end>',\n",
       " '<start> help tom . <end>',\n",
       " '<start> help him . <end>',\n",
       " '<start> hi , guys . <end>',\n",
       " '<start> hi , guys . <end>',\n",
       " '<start> hi , guys . <end>',\n",
       " '<start> hi , guys . <end>',\n",
       " '<start> hi , guys . <end>',\n",
       " '<start> hi , guys . <end>',\n",
       " '<start> how cute ! <end>',\n",
       " '<start> how deep ? <end>',\n",
       " '<start> how deep ? <end>',\n",
       " '<start> humor me . <end>',\n",
       " '<start> humor me . <end>',\n",
       " '<start> hurry up . <end>',\n",
       " '<start> hurry up . <end>',\n",
       " '<start> i agreed . <end>',\n",
       " '<start> i agreed . <end>',\n",
       " '<start> i agreed . <end>',\n",
       " '<start> i am fat . <end>',\n",
       " '<start> i am old . <end>',\n",
       " '<start> i ate it . <end>',\n",
       " '<start> i ate it . <end>',\n",
       " '<start> i can go . <end>',\n",
       " '<start> i did ok . <end>',\n",
       " '<start> i did it . <end>',\n",
       " '<start> i failed . <end>',\n",
       " '<start> i forgot . <end>',\n",
       " '<start> i get by . <end>',\n",
       " '<start> i get it . <end>',\n",
       " '<start> i got it . <end>',\n",
       " '<start> i phoned . <end>',\n",
       " '<start> i refuse . <end>',\n",
       " '<start> i resign . <end>',\n",
       " '<start> i resign . <end>',\n",
       " '<start> i saw it . <end>',\n",
       " '<start> i smiled . <end>',\n",
       " '<start> i stayed . <end>',\n",
       " '<start> i talked . <end>',\n",
       " '<start> i talked . <end>',\n",
       " '<start> i talked . <end>',\n",
       " '<start> i talked . <end>',\n",
       " '<start> i use it . <end>',\n",
       " '<start> i waited . <end>',\n",
       " '<start> i ll pay . <end>',\n",
       " '<start> i m back . <end>',\n",
       " '<start> i m back . <end>',\n",
       " '<start> i m bald . <end>',\n",
       " '<start> i m bald . <end>',\n",
       " '<start> i m calm . <end>',\n",
       " '<start> i m cool . <end>',\n",
       " '<start> i m done . <end>',\n",
       " '<start> i m easy . <end>',\n",
       " '<start> i m fair . <end>',\n",
       " '<start> i m fine . <end>',\n",
       " '<start> i m free ! <end>',\n",
       " '<start> i m free . <end>',\n",
       " '<start> i m full . <end>',\n",
       " '<start> i m full . <end>',\n",
       " '<start> i m full . <end>',\n",
       " '<start> i m here . <end>',\n",
       " '<start> i m home . <end>',\n",
       " '<start> i m hurt . <end>',\n",
       " '<start> i m late . <end>',\n",
       " '<start> i m lazy . <end>',\n",
       " '<start> i m lost . <end>',\n",
       " '<start> i m mean . <end>',\n",
       " '<start> i m next . <end>',\n",
       " '<start> i m okay . <end>',\n",
       " '<start> i m poor . <end>',\n",
       " '<start> i m rich . <end>',\n",
       " '<start> i m rich . <end>',\n",
       " '<start> i m safe . <end>',\n",
       " '<start> i m sick . <end>',\n",
       " '<start> i m thin . <end>',\n",
       " '<start> i m tidy . <end>',\n",
       " '<start> i m warm . <end>',\n",
       " '<start> i m weak . <end>',\n",
       " '<start> i m wise . <end>',\n",
       " '<start> i ve won . <end>',\n",
       " '<start> it helps . <end>',\n",
       " '<start> it hurts . <end>',\n",
       " '<start> it works . <end>',\n",
       " '<start> it s tom . <end>',\n",
       " '<start> it s fun . <end>',\n",
       " '<start> it s his . <end>',\n",
       " '<start> it s new . <end>',\n",
       " '<start> it s odd . <end>',\n",
       " '<start> it s old . <end>',\n",
       " '<start> it s red . <end>',\n",
       " '<start> it s sad . <end>',\n",
       " '<start> keep out ! <end>',\n",
       " '<start> keep out . <end>',\n",
       " '<start> kiss tom . <end>',\n",
       " '<start> kiss tom . <end>',\n",
       " '<start> kiss tom . <end>',\n",
       " '<start> leave it . <end>',\n",
       " '<start> leave me . <end>',\n",
       " '<start> leave us . <end>',\n",
       " '<start> let s go ! <end>',\n",
       " '<start> let s go ! <end>',\n",
       " '<start> look out ! <end>',\n",
       " '<start> marry me . <end>',\n",
       " '<start> may i go ? <end>',\n",
       " '<start> save tom . <end>',\n",
       " '<start> she came . <end>',\n",
       " '<start> she died . <end>',\n",
       " '<start> she runs . <end>',\n",
       " '<start> sit down ! <end>',\n",
       " '<start> sit down . <end>',\n",
       " '<start> sit here . <end>',\n",
       " '<start> speak up ! <end>',\n",
       " '<start> speak up ! <end>',\n",
       " '<start> speak up ! <end>',\n",
       " '<start> stand by . <end>',\n",
       " '<start> stand by . <end>',\n",
       " '<start> stand up ! <end>',\n",
       " '<start> stand up ! <end>',\n",
       " '<start> stay put . <end>',\n",
       " '<start> stop tom . <end>',\n",
       " '<start> take tom . <end>',\n",
       " '<start> tell tom . <end>',\n",
       " '<start> terrific ! <end>',\n",
       " '<start> terrific ! <end>',\n",
       " '<start> they won . <end>',\n",
       " '<start> tom came . <end>',\n",
       " '<start> tom died . <end>',\n",
       " '<start> tom fell . <end>',\n",
       " '<start> tom knew . <end>',\n",
       " '<start> tom knew . <end>',\n",
       " '<start> tom left . <end>',\n",
       " '<start> tom lied . <end>',\n",
       " '<start> tom lies . <end>',\n",
       " '<start> tom lost . <end>',\n",
       " '<start> tom paid . <end>',\n",
       " '<start> tom quit . <end>',\n",
       " '<start> tom swam . <end>',\n",
       " '<start> tom wept . <end>',\n",
       " '<start> tom s up . <end>',\n",
       " '<start> too late . <end>',\n",
       " '<start> trust me . <end>',\n",
       " '<start> try hard . <end>',\n",
       " '<start> try some . <end>',\n",
       " '<start> try some . <end>',\n",
       " '<start> try some . <end>',\n",
       " '<start> try this . <end>',\n",
       " '<start> try this . <end>',\n",
       " '<start> try this . <end>',\n",
       " '<start> use this . <end>',\n",
       " '<start> warn tom . <end>',\n",
       " '<start> warn tom . <end>',\n",
       " '<start> warn tom . <end>',\n",
       " '<start> warn tom . <end>',\n",
       " '<start> watch me . <end>',\n",
       " '<start> watch me . <end>',\n",
       " '<start> watch me . <end>',\n",
       " '<start> watch us . <end>',\n",
       " '<start> watch us . <end>',\n",
       " '<start> we agree . <end>',\n",
       " '<start> we tried . <end>',\n",
       " '<start> we ll go . <end>',\n",
       " '<start> we re ok . <end>',\n",
       " '<start> what for ? <end>',\n",
       " '<start> what fun ! <end>',\n",
       " '<start> who am i ? <end>',\n",
       " '<start> who came ? <end>',\n",
       " '<start> who died ? <end>',\n",
       " '<start> who fell ? <end>',\n",
       " '<start> who fell ? <end>',\n",
       " '<start> who quit ? <end>',\n",
       " '<start> who quit ? <end>',\n",
       " '<start> who swam ? <end>',\n",
       " '<start> who s he ? <end>',\n",
       " '<start> write me . <end>',\n",
       " '<start> after you . <end>',\n",
       " '<start> after you . <end>',\n",
       " '<start> after you . <end>',\n",
       " '<start> after you . <end>',\n",
       " '<start> after you . <end>',\n",
       " '<start> aim . fire ! <end>',\n",
       " '<start> answer me . <end>',\n",
       " '<start> answer me . <end>',\n",
       " '<start> answer me . <end>',\n",
       " '<start> birds fly . <end>',\n",
       " '<start> bless you . <end>',\n",
       " '<start> call home ! <end>',\n",
       " '<start> calm down . <end>',\n",
       " '<start> calm down . <end>',\n",
       " '<start> calm down . <end>',\n",
       " '<start> calm down . <end>',\n",
       " '<start> can we go ? <end>',\n",
       " '<start> can we go ? <end>',\n",
       " '<start> can we go ? <end>',\n",
       " '<start> catch tom . <end>',\n",
       " '<start> catch him . <end>',\n",
       " '<start> catch him . <end>',\n",
       " '<start> catch him . <end>',\n",
       " '<start> catch him . <end>',\n",
       " '<start> come back . <end>',\n",
       " '<start> come here . <end>',\n",
       " '<start> come here . <end>',\n",
       " '<start> come here . <end>',\n",
       " '<start> come home . <end>',\n",
       " '<start> come over . <end>',\n",
       " '<start> come over . <end>',\n",
       " '<start> come over . <end>',\n",
       " '<start> come over . <end>',\n",
       " '<start> come soon . <end>',\n",
       " '<start> do it now . <end>',\n",
       " '<start> dogs bark . <end>',\n",
       " '<start> don t ask . <end>',\n",
       " '<start> don t cry . <end>',\n",
       " '<start> don t cry . <end>',\n",
       " '<start> don t cry . <end>',\n",
       " '<start> don t cry . <end>',\n",
       " '<start> don t lie . <end>',\n",
       " '<start> don t run . <end>',\n",
       " '<start> fantastic ! <end>',\n",
       " '<start> fantastic ! <end>',\n",
       " '<start> fantastic ! <end>',\n",
       " '<start> feel this . <end>',\n",
       " '<start> feel this . <end>',\n",
       " '<start> feel this . <end>',\n",
       " '<start> feel this . <end>',\n",
       " '<start> feel this . <end>',\n",
       " '<start> follow me . <end>',\n",
       " '<start> follow me . <end>',\n",
       " '<start> follow us . <end>',\n",
       " '<start> forget it . <end>',\n",
       " '<start> forget me . <end>',\n",
       " '<start> forget me . <end>',\n",
       " '<start> forget me . <end>',\n",
       " '<start> forget me . <end>',\n",
       " '<start> get ready . <end>',\n",
       " '<start> go for it . <end>',\n",
       " '<start> go for it . <end>',\n",
       " '<start> go get it . <end>',\n",
       " '<start> go get it . <end>',\n",
       " '<start> go get it . <end>',\n",
       " '<start> go inside . <end>',\n",
       " '<start> go to bed . <end>',\n",
       " '<start> grab that . <end>',\n",
       " '<start> grab this . <end>',\n",
       " '<start> have some . <end>',\n",
       " '<start> have some . <end>',\n",
       " '<start> have some . <end>',\n",
       " '<start> he is old . <end>',\n",
       " '<start> he is old . <end>',\n",
       " '<start> he shaved . <end>',\n",
       " '<start> he smiled . <end>',\n",
       " '<start> he s a dj . <end>',\n",
       " '<start> he s fast . <end>',\n",
       " '<start> he s good . <end>',\n",
       " '<start> he s rich . <end>',\n",
       " '<start> he s rich . <end>',\n",
       " '<start> here i am . <end>',\n",
       " '<start> hold this . <end>',\n",
       " '<start> how awful ! <end>',\n",
       " '<start> how weird ! <end>',\n",
       " '<start> how s tom ? <end>',\n",
       " '<start> humor tom . <end>',\n",
       " '<start> i am busy . <end>',\n",
       " '<start> i am full . <end>',\n",
       " '<start> i am full . <end>',\n",
       " '<start> i am good . <end>',\n",
       " '<start> i am here . <end>',\n",
       " '<start> i am sick . <end>',\n",
       " '<start> i am weak . <end>',\n",
       " '<start> i beg you . <end>',\n",
       " '<start> i beg you . <end>',\n",
       " '<start> i can fly . <end>',\n",
       " '<start> i can run . <end>',\n",
       " '<start> i can run . <end>',\n",
       " '<start> i can ski . <end>',\n",
       " '<start> i cringed . <end>',\n",
       " '<start> i fainted . <end>',\n",
       " '<start> i fainted . <end>',\n",
       " '<start> i gave up . <end>',\n",
       " '<start> i gave up . <end>',\n",
       " '<start> i gave up . <end>',\n",
       " '<start> i gave up . <end>',\n",
       " '<start> i get you . <end>',\n",
       " '<start> i get you . <end>',\n",
       " '<start> i get you . <end>',\n",
       " '<start> i got hit . <end>',\n",
       " '<start> i got hit . <end>',\n",
       " '<start> i hate it . <end>',\n",
       " '<start> i hate it . <end>',\n",
       " '<start> i hate it . <end>',\n",
       " '<start> i hit tom . <end>',\n",
       " '<start> i hope so . <end>',\n",
       " '<start> i knew it . <end>',\n",
       " '<start> i laughed . <end>',\n",
       " '<start> i like it . <end>',\n",
       " '<start> i love it ! <end>',\n",
       " '<start> i love it . <end>',\n",
       " '<start> i mean it ! <end>',\n",
       " '<start> i mean it . <end>',\n",
       " '<start> i mean it . <end>',\n",
       " '<start> i miss it . <end>',\n",
       " '<start> i miss it . <end>',\n",
       " '<start> i miss it . <end>',\n",
       " '<start> i need it . <end>',\n",
       " '<start> i saw tom . <end>',\n",
       " '<start> i saw him . <end>',\n",
       " '<start> i saw him . <end>',\n",
       " '<start> i saw one . <end>',\n",
       " '<start> i saw one . <end>',\n",
       " '<start> i saw one . <end>',\n",
       " '<start> i saw you . <end>',\n",
       " '<start> i saw you . <end>',\n",
       " '<start> i see tom . <end>',\n",
       " '<start> i tripped . <end>',\n",
       " '<start> i ll cook . <end>',\n",
       " '<start> i ll cook . <end>',\n",
       " '<start> i ll live . <end>',\n",
       " '<start> i ll sing . <end>',\n",
       " '<start> i ll stop . <end>',\n",
       " '<start> i ll stop . <end>',\n",
       " '<start> i ll wait . <end>',\n",
       " '<start> i ll wait . <end>',\n",
       " '<start> i ll walk . <end>',\n",
       " '<start> i ll walk . <end>',\n",
       " '<start> i ll work . <end>',\n",
       " '<start> i m a man . <end>',\n",
       " '<start> i m a pro . <end>',\n",
       " '<start> i m alone . <end>',\n",
       " '<start> i m alone . <end>',\n",
       " '<start> i m alone . <end>',\n",
       " '<start> i m alone . <end>',\n",
       " '<start> i m angry . <end>',\n",
       " '<start> i m angry . <end>',\n",
       " '<start> i m awake . <end>',\n",
       " '<start> i m blind . <end>',\n",
       " '<start> i m broke . <end>',\n",
       " '<start> i m broke . <end>',\n",
       " '<start> i m broke . <end>',\n",
       " '<start> i m broke . <end>',\n",
       " '<start> i m crazy . <end>',\n",
       " '<start> i m drunk . <end>',\n",
       " '<start> i m drunk . <end>',\n",
       " '<start> i m drunk . <end>',\n",
       " '<start> i m dying . <end>',\n",
       " '<start> i m first . <end>',\n",
       " '<start> i m first . <end>',\n",
       " '<start> i m first . <end>',\n",
       " '<start> i m first . <end>',\n",
       " '<start> i m happy . <end>',\n",
       " '<start> i m happy . <end>',\n",
       " '<start> i m loved . <end>',\n",
       " '<start> i m loved . <end>',\n",
       " '<start> i m obese . <end>',\n",
       " '<start> i m ready . <end>',\n",
       " '<start> i m sorry . <end>',\n",
       " '<start> i m tired . <end>',\n",
       " '<start> i m tired . <end>',\n",
       " '<start> i m yours . <end>',\n",
       " '<start> i m yours . <end>',\n",
       " '<start> i m yours . <end>',\n",
       " '<start> i ve lost . <end>',\n",
       " '<start> ignore it . <end>',\n",
       " '<start> ignore it . <end>',\n",
       " '<start> is tom ok ? <end>',\n",
       " '<start> is tom in ? <end>',\n",
       " '<start> is it bad ? <end>',\n",
       " '<start> is it bad ? <end>',\n",
       " '<start> is it far ? <end>',\n",
       " '<start> is it you ? <end>',\n",
       " '<start> it burned . <end>',\n",
       " '<start> it failed . <end>',\n",
       " '<start> it failed . <end>',\n",
       " '<start> it failed . <end>',\n",
       " '<start> it is new . <end>',\n",
       " '<start> it rained . <end>',\n",
       " '<start> it snowed . <end>',\n",
       " '<start> it stinks . <end>',\n",
       " '<start> it worked . <end>',\n",
       " '<start> it s . <end>',\n",
       " '<start> it s . <end>',\n",
       " '<start> it s a tv . <end>',\n",
       " '<start> it s cold . <end>',\n",
       " '<start> it s cold . <end>',\n",
       " '<start> it s cool . <end>',\n",
       " '<start> it s cool . <end>',\n",
       " '<start> it s dark . <end>',\n",
       " '<start> it s done ! <end>',\n",
       " '<start> it s fine . <end>',\n",
       " '<start> it s good . <end>',\n",
       " '<start> it s good . <end>',\n",
       " '<start> it s here . <end>',\n",
       " '<start> it s hers . <end>',\n",
       " '<start> it s late . <end>',\n",
       " '<start> it s mine . <end>',\n",
       " '<start> it s mine . <end>',\n",
       " '<start> it s nice . <end>',\n",
       " '<start> it s nice . <end>',\n",
       " '<start> it s okay . <end>',\n",
       " '<start> it s okay . <end>',\n",
       " '<start> it s ours . <end>',\n",
       " '<start> it s ours . <end>',\n",
       " '<start> it s over . <end>',\n",
       " '<start> it s over . <end>',\n",
       " '<start> it s time . <end>',\n",
       " '<start> it s time . <end>',\n",
       " '<start> it s time . <end>',\n",
       " '<start> it s time . <end>',\n",
       " '<start> it s true ! <end>',\n",
       " '<start> it s true . <end>',\n",
       " '<start> it s work . <end>',\n",
       " '<start> keep them . <end>',\n",
       " '<start> keep them . <end>',\n",
       " '<start> keep them . <end>',\n",
       " '<start> keep this . <end>',\n",
       " '<start> keep this . <end>',\n",
       " '<start> keep this . <end>',\n",
       " '<start> keep this . <end>',\n",
       " '<start> keep this . <end>',\n",
       " '<start> keep warm . <end>',\n",
       " '<start> keep warm . <end>',\n",
       " '<start> keep warm . <end>',\n",
       " '<start> keep warm . <end>',\n",
       " '<start> keep warm . <end>',\n",
       " '<start> keep warm . <end>',\n",
       " '<start> keep warm . <end>',\n",
       " '<start> keep warm . <end>',\n",
       " '<start> leave tom . <end>',\n",
       " '<start> leave tom . <end>',\n",
       " '<start> leave tom . <end>',\n",
       " '<start> leave now . <end>',\n",
       " '<start> leave now . <end>',\n",
       " '<start> leave now . <end>',\n",
       " '<start> let me go ! <end>',\n",
       " '<start> let me go ! <end>',\n",
       " '<start> let me go ! <end>',\n",
       " '<start> let me go . <end>',\n",
       " '<start> let me in . <end>',\n",
       " '<start> let me in . <end>',\n",
       " '<start> let us in . <end>',\n",
       " '<start> let s eat . <end>',\n",
       " '<start> let s see . <end>',\n",
       " '<start> let s try ! <end>',\n",
       " '<start> lie still . <end>',\n",
       " '<start> lie still . <end>',\n",
       " '<start> listen up . <end>',\n",
       " '<start> look away . <end>',\n",
       " '<start> look away . <end>',\n",
       " '<start> look away . <end>',\n",
       " '<start> look away . <end>',\n",
       " '<start> look back ! <end>',\n",
       " '<start> look back . <end>',\n",
       " '<start> look back . <end>',\n",
       " '<start> look back . <end>',\n",
       " '<start> look here . <end>',\n",
       " '<start> look here . <end>',\n",
       " '<start> look here . <end>',\n",
       " '<start> loosen it . <end>',\n",
       " '<start> loosen it . <end>',\n",
       " '<start> loosen it . <end>',\n",
       " '<start> loosen it . <end>',\n",
       " '<start> move over . <end>',\n",
       " '<start> move over . <end>',\n",
       " '<start> move over . <end>',\n",
       " '<start> move over . <end>',\n",
       " '<start> nice shot ! <end>',\n",
       " '<start> of course ! <end>',\n",
       " '<start> open fire ! <end>',\n",
       " '<start> open fire ! <end>',\n",
       " '<start> pardon me ? <end>',\n",
       " '<start> please go . <end>',\n",
       " '<start> please go . <end>',\n",
       " '<start> please go . <end>',\n",
       " '<start> please go . <end>',\n",
       " '<start> put it on . <end>',\n",
       " '<start> put it on . <end>',\n",
       " '<start> read this . <end>',\n",
       " '<start> read this . <end>',\n",
       " '<start> read this . <end>',\n",
       " '<start> read this . <end>',\n",
       " '<start> say hello . <end>',\n",
       " '<start> search me . <end>',\n",
       " '<start> see above . <end>',\n",
       " '<start> see above . <end>',\n",
       " '<start> seize him ! <end>',\n",
       " '<start> seize him ! <end>',\n",
       " '<start> seize him ! <end>',\n",
       " '<start> seize him ! <end>',\n",
       " '<start> seize him ! <end>',\n",
       " '<start> seriously ? <end>',\n",
       " '<start> she tried . <end>',\n",
       " '<start> she tried . <end>',\n",
       " '<start> she walks . <end>',\n",
       " '<start> she walks . <end>',\n",
       " '<start> she walks . <end>',\n",
       " '<start> she s hot . <end>',\n",
       " '<start> she s hot . <end>',\n",
       " '<start> she s hot . <end>',\n",
       " '<start> she s hot . <end>',\n",
       " '<start> she s hot . <end>',\n",
       " '<start> sign here . <end>',\n",
       " '<start> sign this . <end>',\n",
       " '<start> sign this . <end>',\n",
       " '<start> sign this . <end>',\n",
       " '<start> sign this . <end>',\n",
       " '<start> sign this . <end>',\n",
       " '<start> sit still . <end>',\n",
       " '<start> sit still . <end>',\n",
       " '<start> sit there . <end>',\n",
       " '<start> sit tight . <end>',\n",
       " '<start> slow down . <end>',\n",
       " '<start> slow down . <end>',\n",
       " '<start> stay away . <end>',\n",
       " '<start> stay away . <end>',\n",
       " '<start> stay calm . <end>',\n",
       " '<start> stay calm . <end>',\n",
       " '<start> stay here . <end>',\n",
       " '<start> step back . <end>',\n",
       " '<start> stop here . <end>',\n",
       " '<start> stop here . <end>',\n",
       " '<start> stop here . <end>',\n",
       " '<start> stop here . <end>',\n",
       " '<start> stop here . <end>',\n",
       " '<start> stop here . <end>',\n",
       " '<start> stop here . <end>',\n",
       " '<start> stop that . <end>',\n",
       " '<start> stop them . <end>',\n",
       " '<start> stop them . <end>',\n",
       " '<start> take care ! <end>',\n",
       " '<start> take care ! <end>',\n",
       " '<start> take care . <end>',\n",
       " '<start> take care . <end>',\n",
       " '<start> take mine . <end>',\n",
       " '<start> take mine . <end>',\n",
       " '<start> take over . <end>',\n",
       " '<start> take over . <end>',\n",
       " '<start> take over . <end>',\n",
       " '<start> take this . <end>',\n",
       " '<start> take this . <end>',\n",
       " '<start> take this . <end>',\n",
       " '<start> take this . <end>',\n",
       " '<start> thank you . <end>',\n",
       " '<start> thank you . <end>',\n",
       " '<start> thank you . <end>',\n",
       " '<start> that s it . <end>',\n",
       " '<start> that s me . <end>',\n",
       " '<start> that s me . <end>',\n",
       " '<start> then what ? <end>',\n",
       " '<start> they fell . <end>',\n",
       " '<start> they left . <end>',\n",
       " '<start> they left . <end>',\n",
       " '<start> they left . <end>',\n",
       " '<start> they lost . <end>',\n",
       " '<start> tom bowed . <end>',\n",
       " '<start> tom cared . <end>',\n",
       " '<start> tom cared . <end>',\n",
       " '<start> tom cared . <end>',\n",
       " '<start> tom cares . <end>',\n",
       " '<start> tom cares . <end>',\n",
       " '<start> tom cried . <end>',\n",
       " '<start> tom dozed . <end>',\n",
       " '<start> tom drove . <end>',\n",
       " '<start> tom is ok . <end>',\n",
       " '<start> tom is in . <end>',\n",
       " '<start> tom is up . <end>',\n",
       " '<start> tom knits . <end>',\n",
       " '<start> tom knows . <end>',\n",
       " '<start> tom moved . <end>',\n",
       " '<start> tom moved . <end>',\n",
       " '<start> tom rocks . <end>',\n",
       " '<start> tom stood . <end>',\n",
       " '<start> tom swims . <end>',\n",
       " '<start> tom swore . <end>',\n",
       " '<start> tom tried . <end>',\n",
       " '<start> tom tries . <end>',\n",
       " '<start> tom voted . <end>',\n",
       " '<start> tom walks . <end>',\n",
       " '<start> tom waved . <end>',\n",
       " '<start> tom works . <end>',\n",
       " '<start> tom ll go . <end>',\n",
       " '<start> tom s fat . <end>',\n",
       " '<start> tom s mad . <end>',\n",
       " '<start> tom s sad . <end>',\n",
       " '<start> tom s shy . <end>',\n",
       " '<start> trust tom . <end>',\n",
       " '<start> try again . <end>',\n",
       " '<start> try again . <end>',\n",
       " '<start> try again . <end>',\n",
       " '<start> try it on . <end>',\n",
       " '<start> wait here . <end>',\n",
       " '<start> wait here . <end>',\n",
       " '<start> wait here . <end>',\n",
       " '<start> wait here . <end>',\n",
       " '<start> watch tom . <end>',\n",
       " '<start> watch out ! <end>',\n",
       " '<start> we can go . <end>',\n",
       " '<start> we can go . <end>',\n",
       " '<start> we can go . <end>',\n",
       " '<start> we failed . <end>',\n",
       " '<start> we failed . <end>',\n",
       " '<start> we forgot . <end>',\n",
       " '<start> we saw it . <end>',\n",
       " '<start> we saw it . <end>',\n",
       " '<start> we talked . <end>',\n",
       " '<start> we waited . <end>',\n",
       " '<start> we ll see . <end>',\n",
       " '<start> we ll see . <end>',\n",
       " '<start> we ll try . <end>',\n",
       " '<start> we ve won ! <end>',\n",
       " '<start> what s up ? <end>',\n",
       " '<start> who cares ? <end>',\n",
       " '<start> who is he ? <end>',\n",
       " '<start> who is it ? <end>',\n",
       " '<start> who knows ? <end>',\n",
       " '<start> who stood ? <end>',\n",
       " '<start> who ll go ? <end>',\n",
       " '<start> who s tom ? <end>',\n",
       " '<start> write tom . <end>',\n",
       " '<start> you drive . <end>',\n",
       " '<start> you start . <end>',\n",
       " '<start> you tried . <end>',\n",
       " '<start> you re ok . <end>',\n",
       " '<start> you re ok . <end>',\n",
       " '<start> aim higher . <end>',\n",
       " '<start> aim higher . <end>',\n",
       " '<start> all aboard ! <end>',\n",
       " '<start> am i right ? <end>',\n",
       " '<start> am i wrong ? <end>',\n",
       " '<start> am i wrong ? <end>',\n",
       " '<start> answer tom . <end>',\n",
       " '<start> answer tom . <end>',\n",
       " '<start> answer tom . <end>',\n",
       " '<start> are you ? <end>',\n",
       " '<start> are you ? <end>',\n",
       " '<start> are you ok ? <end>',\n",
       " '<start> are you in ? <end>',\n",
       " '<start> are you in ? <end>',\n",
       " '<start> are you up ? <end>',\n",
       " '<start> ask anyone . <end>',\n",
       " '<start> ask anyone . <end>',\n",
       " '<start> ask anyone . <end>',\n",
       " '<start> ask anyone . <end>',\n",
       " '<start> ask around . <end>',\n",
       " '<start> ask around . <end>',\n",
       " '<start> be careful . <end>',\n",
       " '<start> be careful . <end>',\n",
       " '<start> be content . <end>',\n",
       " '<start> be on time . <end>',\n",
       " '<start> be on time . <end>',\n",
       " '<start> be patient . <end>',\n",
       " '<start> be serious . <end>',\n",
       " '<start> birds sing . <end>',\n",
       " '<start> birds sing . <end>',\n",
       " '<start> bring food . <end>',\n",
       " '<start> bring help . <end>',\n",
       " '<start> bring wine . <end>',\n",
       " '<start> can i come ? <end>',\n",
       " '<start> can i come ? <end>',\n",
       " '<start> can i come ? <end>',\n",
       " '<start> can i help ? <end>',\n",
       " '<start> can i stay ? <end>',\n",
       " '<start> carry this . <end>',\n",
       " '<start> check that . <end>',\n",
       " '<start> check this . <end>',\n",
       " '<start> choose one . <end>',\n",
       " '<start> come again . <end>',\n",
       " '<start> come alone . <end>',\n",
       " '<start> come along . <end>',\n",
       " '<start> come along . <end>',\n",
       " '<start> come early . <end>',\n",
       " '<start> come early . <end>',\n",
       " '<start> come early . <end>',\n",
       " '<start> come early . <end>',\n",
       " '<start> come on in ! <end>',\n",
       " '<start> come on in ! <end>',\n",
       " '<start> come on in ! <end>',\n",
       " '<start> come on in . <end>',\n",
       " '<start> come on in . <end>',\n",
       " '<start> come quick ! <end>',\n",
       " '<start> come quick ! <end>',\n",
       " '<start> come to me . <end>',\n",
       " '<start> come to me . <end>',\n",
       " '<start> come to us . <end>',\n",
       " '<start> come to us . <end>',\n",
       " '<start> cut it out ! <end>',\n",
       " '<start> did tom go ? <end>',\n",
       " '<start> do come in ! <end>',\n",
       " '<start> do come in ! <end>',\n",
       " '<start> do come in ! <end>',\n",
       " '<start> do come in . <end>',\n",
       " '<start> do come in . <end>',\n",
       " '<start> do come in . <end>',\n",
       " '<start> do come in . <end>',\n",
       " '<start> do men cry ? <end>',\n",
       " '<start> don t come . <end>',\n",
       " '<start> don t jump ! <end>',\n",
       " '<start> don t look . <end>',\n",
       " '<start> don t move ! <end>',\n",
       " '<start> don t move . <end>',\n",
       " '<start> don t move . <end>',\n",
       " '<start> don t move . <end>',\n",
       " '<start> don t sing . <end>',\n",
       " '<start> don t sing . <end>',\n",
       " '<start> don t stop . <end>',\n",
       " '<start> don t talk ! <end>',\n",
       " '<start> don t talk . <end>',\n",
       " '<start> don t wait . <end>',\n",
       " '<start> don t wait . <end>',\n",
       " '<start> don t wait . <end>',\n",
       " '<start> don t yell . <end>',\n",
       " '<start> eat slowly . <end>',\n",
       " '<start> eat slowly . <end>',\n",
       " '<start> fire burns . <end>',\n",
       " '<start> follow tom . <end>',\n",
       " '<start> follow tom . <end>',\n",
       " '<start> follow tom . <end>',\n",
       " '<start> follow tom . <end>',\n",
       " '<start> follow him . <end>',\n",
       " '<start> follow him . <end>',\n",
       " '<start> forget tom . <end>',\n",
       " '<start> forget tom . <end>',\n",
       " '<start> forget tom . <end>',\n",
       " '<start> forget him . <end>',\n",
       " '<start> forgive us . <end>',\n",
       " '<start> forgive us . <end>',\n",
       " '<start> get a life . <end>',\n",
       " '<start> get inside . <end>',\n",
       " '<start> get to bed . <end>',\n",
       " '<start> give it up . <end>',\n",
       " '<start> go on home . <end>',\n",
       " '<start> go on home . <end>',\n",
       " '<start> go see tom . <end>',\n",
       " '<start> go to work . <end>',\n",
       " '<start> god exists . <end>',\n",
       " '<start> have faith . <end>',\n",
       " '<start> have faith . <end>',\n",
       " '<start> have faith . <end>',\n",
       " '<start> have faith . <end>',\n",
       " '<start> he ate out . <end>',\n",
       " '<start> he coughed . <end>',\n",
       " '<start> he gave in . <end>',\n",
       " '<start> he gave up . <end>',\n",
       " '<start> he gave up . <end>',\n",
       " '<start> he gave up . <end>',\n",
       " '<start> he gave up . <end>',\n",
       " '<start> he hung up . <end>',\n",
       " '<start> he hung up . <end>',\n",
       " ...)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,   12,   40, 1068,    3,    2,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentence = u'todo sobre mi madre .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> todo sobre mi madre . <end>'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_sentence(sample_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pairs = [preprocess_sentence(sample_sentence)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not zip",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-a3a01901bf39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mword_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-80-3298d52de637>\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(path, num_examples)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# 3. Return word pairs in the format: [ENGLISH, SPANISH]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'UTF-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0mword_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreprocess_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not zip"
     ]
    }
   ],
   "source": [
    "create_dataset(zip(*word_pairs), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-d5d17eb90178>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mword_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-80-3298d52de637>\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m     64\u001b[0m   lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n\u001b[1;32m     65\u001b[0m       filters='')\n\u001b[0;32m---> 66\u001b[0;31m   \u001b[0mlang_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlang_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/transformer_env/lib/python3.7/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mfit_on_texts\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    223\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                                             self.split)\n\u001b[0m\u001b[1;32m    226\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_counts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/transformer_env/lib/python3.7/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mtext_to_word_sequence\u001b[0;34m(text, filters, lower, split)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "tokenize(zip(*word_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_code = tokenize(tuple('<start> todo sobre mi madre . <end>'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_code = np.squeeze(sample_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  7,  1,  8,  2,  1,  9,  0,  1,  3,  4,  3,  0,  7,  3, 11,  2,\n",
       "        5,  0, 10, 12,  0, 10,  8,  4,  2,  5,  0, 13,  0,  6,  5, 14,  4,\n",
       "        9], dtype=int32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,   12,   40, 1068,    3,    2,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 ----> ¿\n",
      "1 ----> <start>\n",
      "2 ----> <end>\n",
      "1 ----> <start>\n",
      "7 ----> es\n",
      "1 ----> <start>\n",
      "8 ----> no\n",
      "3 ----> .\n",
      "4 ----> tom\n",
      "5 ----> ?\n",
      "9 ----> el\n",
      "5 ----> ?\n",
      "10 ----> a\n",
      "2 ----> <end>\n",
      "3 ----> .\n",
      "4 ----> tom\n",
      "11 ----> que\n"
     ]
    }
   ],
   "source": [
    "convert(inp_lang, sample_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "12 ----> me\n",
      "40 ----> gusta\n",
      "1068 ----> esquiar\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "4 ----> i\n",
      "35 ----> like\n",
      "975 ----> skiing\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'t'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a243e68ceafb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Input Language; index to word mapping\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-2cbb422c80bc>\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(lang, tensor)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m       \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"%d ----> %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 't'"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, sample_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'index_word'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-85575d9cfdbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Input Language; index to word mapping\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Target Language; index to word mapping\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-2cbb422c80bc>\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(lang, tensor)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m       \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"%d ----> %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'index_word'"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[1])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = preprocess_sentence('Mujeres al  de un ataque de nervios')\n",
    "inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 581, 70, 14, 15, 3415, 14, 8345, 2]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<start>': 1,\n",
       " '<end>': 2,\n",
       " '.': 3,\n",
       " 'tom': 4,\n",
       " '?': 5,\n",
       " '¿': 6,\n",
       " 'es': 7,\n",
       " 'no': 8,\n",
       " 'el': 9,\n",
       " 'a': 10,\n",
       " 'que': 11,\n",
       " 'me': 12,\n",
       " 'la': 13,\n",
       " 'de': 14,\n",
       " 'un': 15,\n",
       " 'esta': 16,\n",
       " 'se': 17,\n",
       " 'lo': 18,\n",
       " 'mi': 19,\n",
       " 'en': 20,\n",
       " 'una': 21,\n",
       " 'por': 22,\n",
       " 'te': 23,\n",
       " 'estoy': 24,\n",
       " 'ella': 25,\n",
       " 'yo': 26,\n",
       " '!': 27,\n",
       " 'eso': 28,\n",
       " 'le': 29,\n",
       " 'esto': 30,\n",
       " 'tu': 31,\n",
       " ',': 32,\n",
       " 'los': 33,\n",
       " 'aqui': 34,\n",
       " 'soy': 35,\n",
       " 'muy': 36,\n",
       " 'tengo': 37,\n",
       " 'puedo': 38,\n",
       " 'las': 39,\n",
       " 'gusta': 40,\n",
       " 'mary': 41,\n",
       " 'tiene': 42,\n",
       " 'son': 43,\n",
       " 'con': 44,\n",
       " 'como': 45,\n",
       " 'quien': 46,\n",
       " 'estaba': 47,\n",
       " 'su': 48,\n",
       " 'este': 49,\n",
       " 'favor': 50,\n",
       " 'estas': 51,\n",
       " 'eres': 52,\n",
       " 'quiero': 53,\n",
       " 'ellos': 54,\n",
       " 'fue': 55,\n",
       " 'bien': 56,\n",
       " 'casa': 57,\n",
       " 'ahora': 58,\n",
       " 'tomas': 59,\n",
       " 'donde': 60,\n",
       " 'mas': 61,\n",
       " 'estan': 62,\n",
       " 'nos': 63,\n",
       " 'he': 64,\n",
       " 'solo': 65,\n",
       " 'puede': 66,\n",
       " 'ha': 67,\n",
       " 'era': 68,\n",
       " 'todos': 69,\n",
       " 'al': 70,\n",
       " 'para': 71,\n",
       " 'ir': 72,\n",
       " 'tan': 73,\n",
       " 'todo': 74,\n",
       " 'estamos': 75,\n",
       " 'necesito': 76,\n",
       " 'ya': 77,\n",
       " 'nadie': 78,\n",
       " 'puedes': 79,\n",
       " 'trabajo': 80,\n",
       " 'voy': 81,\n",
       " 'usted': 82,\n",
       " 'tienes': 83,\n",
       " 'demasiado': 84,\n",
       " 'ese': 85,\n",
       " 'nada': 86,\n",
       " 'y': 87,\n",
       " 'hay': 88,\n",
       " 'mucho': 89,\n",
       " 'nunca': 90,\n",
       " 'hizo': 91,\n",
       " 'perro': 92,\n",
       " 'esa': 93,\n",
       " 'algo': 94,\n",
       " 'libro': 95,\n",
       " 'hoy': 96,\n",
       " 'poco': 97,\n",
       " 'dos': 98,\n",
       " 'parece': 99,\n",
       " 'todavia': 100,\n",
       " 'dinero': 101,\n",
       " 'tiempo': 102,\n",
       " 'nuevo': 103,\n",
       " 'sabe': 104,\n",
       " 'somos': 105,\n",
       " 'quiere': 106,\n",
       " 'mis': 107,\n",
       " 'gustan': 108,\n",
       " 'ser': 109,\n",
       " 'nosotros': 110,\n",
       " 'vez': 111,\n",
       " 'coche': 112,\n",
       " 'estar': 113,\n",
       " 'sos': 114,\n",
       " 'feliz': 115,\n",
       " 'va': 116,\n",
       " 'buen': 117,\n",
       " 'tarde': 118,\n",
       " 'ti': 119,\n",
       " 'ahi': 120,\n",
       " 'frances': 121,\n",
       " 'hablar': 122,\n",
       " 'hacer': 123,\n",
       " 'verdad': 124,\n",
       " 'hace': 125,\n",
       " 'creo': 126,\n",
       " 'tenemos': 127,\n",
       " 'ayuda': 128,\n",
       " 'alli': 129,\n",
       " 'boston': 130,\n",
       " 'hombre': 131,\n",
       " 'has': 132,\n",
       " 'deja': 133,\n",
       " 'vi': 134,\n",
       " 've': 135,\n",
       " 'mal': 136,\n",
       " 'alguien': 137,\n",
       " 'auto': 138,\n",
       " 'vamos': 139,\n",
       " 'si': 140,\n",
       " 'mejor': 141,\n",
       " 'siento': 142,\n",
       " 'podria': 143,\n",
       " 'podemos': 144,\n",
       " 'cuando': 145,\n",
       " 'hice': 146,\n",
       " 'vida': 147,\n",
       " 'odio': 148,\n",
       " 'dia': 149,\n",
       " 'conmigo': 150,\n",
       " 'siempre': 151,\n",
       " 'les': 152,\n",
       " 'encanta': 153,\n",
       " 'otra': 154,\n",
       " 'dejame': 155,\n",
       " 'rapido': 156,\n",
       " 'cual': 157,\n",
       " 'ustedes': 158,\n",
       " 'vino': 159,\n",
       " 'tenia': 160,\n",
       " 'puerta': 161,\n",
       " 'bueno': 162,\n",
       " 'ver': 163,\n",
       " 'hacerlo': 164,\n",
       " 'ven': 165,\n",
       " 'tambien': 166,\n",
       " 'os': 167,\n",
       " 'comer': 168,\n",
       " 'buena': 169,\n",
       " 'sus': 170,\n",
       " 'deberia': 171,\n",
       " 'dijo': 172,\n",
       " 'listo': 173,\n",
       " 'padre': 174,\n",
       " 'habitacion': 175,\n",
       " 'habla': 176,\n",
       " 'nuestro': 177,\n",
       " 'realmente': 178,\n",
       " 'ayudar': 179,\n",
       " 'queria': 180,\n",
       " 'hecho': 181,\n",
       " 'mismo': 182,\n",
       " 'nadar': 183,\n",
       " 'cansado': 184,\n",
       " 'ocupado': 185,\n",
       " 'del': 186,\n",
       " 'acabo': 187,\n",
       " 'razon': 188,\n",
       " 'grande': 189,\n",
       " 'noche': 190,\n",
       " 'gracias': 191,\n",
       " 'mira': 192,\n",
       " 'gato': 193,\n",
       " 'miedo': 194,\n",
       " 'manana': 195,\n",
       " 'acuerdo': 196,\n",
       " 'debo': 197,\n",
       " 'cama': 198,\n",
       " 'dije': 199,\n",
       " 'tus': 200,\n",
       " 'espera': 201,\n",
       " 'visto': 202,\n",
       " 'mio': 203,\n",
       " 'tal': 204,\n",
       " 'bastante': 205,\n",
       " 'alto': 206,\n",
       " 'veo': 207,\n",
       " 'ellas': 208,\n",
       " 'necesita': 209,\n",
       " 'dame': 210,\n",
       " 'idea': 211,\n",
       " 'amigos': 212,\n",
       " 'hemos': 213,\n",
       " 'quieres': 214,\n",
       " 'pareces': 215,\n",
       " 'casi': 216,\n",
       " 'estado': 217,\n",
       " 'fui': 218,\n",
       " 'hambre': 219,\n",
       " 'dio': 220,\n",
       " 'agua': 221,\n",
       " 'sabes': 222,\n",
       " 'sabia': 223,\n",
       " 'uno': 224,\n",
       " 'comida': 225,\n",
       " 'problema': 226,\n",
       " 'facil': 227,\n",
       " 'frio': 228,\n",
       " 'fuera': 229,\n",
       " 'lunes': 230,\n",
       " 'amigo': 231,\n",
       " 'duele': 232,\n",
       " 'dejo': 233,\n",
       " 'conozco': 234,\n",
       " 'estos': 235,\n",
       " 'vio': 236,\n",
       " 'madre': 237,\n",
       " 'pronto': 238,\n",
       " 'anos': 239,\n",
       " 'nino': 240,\n",
       " 'loco': 241,\n",
       " 'haz': 242,\n",
       " 'dormir': 243,\n",
       " 'libros': 244,\n",
       " 'puso': 245,\n",
       " 'mano': 246,\n",
       " 'sin': 247,\n",
       " 'television': 248,\n",
       " 'vive': 249,\n",
       " 'ojos': 250,\n",
       " 'menos': 251,\n",
       " 'cantar': 252,\n",
       " 'estuvo': 253,\n",
       " 'hora': 254,\n",
       " 'enfermo': 255,\n",
       " 'amo': 256,\n",
       " 'seguro': 257,\n",
       " 'mundo': 258,\n",
       " 'tienen': 259,\n",
       " 'pelo': 260,\n",
       " 'murio': 261,\n",
       " 'perros': 262,\n",
       " 'perdido': 263,\n",
       " 'joven': 264,\n",
       " 'compre': 265,\n",
       " 'mujer': 266,\n",
       " 'maria': 267,\n",
       " 'nombre': 268,\n",
       " 'contigo': 269,\n",
       " 'viejo': 270,\n",
       " 'hablo': 271,\n",
       " 'triste': 272,\n",
       " 'entrar': 273,\n",
       " 'espero': 274,\n",
       " 'sueno': 275,\n",
       " 'suerte': 276,\n",
       " 'necesitamos': 277,\n",
       " 'estais': 278,\n",
       " 'haciendo': 279,\n",
       " 'reloj': 280,\n",
       " 'perdi': 281,\n",
       " 'hasta': 282,\n",
       " 'momento': 283,\n",
       " 'toma': 284,\n",
       " 'tres': 285,\n",
       " 'queremos': 286,\n",
       " 'sigue': 287,\n",
       " 'viene': 288,\n",
       " 'escuela': 289,\n",
       " 'llave': 290,\n",
       " 'culpa': 291,\n",
       " 'historia': 292,\n",
       " 'vete': 293,\n",
       " 'fuerte': 294,\n",
       " 'calor': 295,\n",
       " 'vas': 296,\n",
       " 'cafe': 297,\n",
       " 'gran': 298,\n",
       " 'temprano': 299,\n",
       " 'cerca': 300,\n",
       " 'cerveza': 301,\n",
       " 'llorar': 302,\n",
       " 'irme': 303,\n",
       " 'jugar': 304,\n",
       " 'perdio': 305,\n",
       " 'ido': 306,\n",
       " 'sola': 307,\n",
       " 'venir': 308,\n",
       " 'vivo': 309,\n",
       " 'di': 310,\n",
       " 'necesitas': 311,\n",
       " 'seas': 312,\n",
       " 'hijo': 313,\n",
       " 'media': 314,\n",
       " 'cuanto': 315,\n",
       " 'leer': 316,\n",
       " 'ingles': 317,\n",
       " 'semana': 318,\n",
       " 'mia': 319,\n",
       " 'trabaja': 320,\n",
       " 'cosas': 321,\n",
       " 'gusto': 322,\n",
       " 'pagar': 323,\n",
       " 'pueden': 324,\n",
       " 'tuve': 325,\n",
       " 'han': 326,\n",
       " 'gente': 327,\n",
       " 'manos': 328,\n",
       " 'libre': 329,\n",
       " 'salir': 330,\n",
       " 'esperar': 331,\n",
       " 'estupido': 332,\n",
       " 'leche': 333,\n",
       " 'cierto': 334,\n",
       " 'lista': 335,\n",
       " 'dificil': 336,\n",
       " 'muerto': 337,\n",
       " 'llama': 338,\n",
       " 'borracho': 339,\n",
       " 'vale': 340,\n",
       " 'bebe': 341,\n",
       " 'camino': 342,\n",
       " 'duro': 343,\n",
       " 'vos': 344,\n",
       " 'estaban': 345,\n",
       " 'zapatos': 346,\n",
       " 'sea': 347,\n",
       " 'llego': 348,\n",
       " 'primero': 349,\n",
       " 'hazlo': 350,\n",
       " 'trabajar': 351,\n",
       " 'quedate': 352,\n",
       " 'comiendo': 353,\n",
       " 'decir': 354,\n",
       " 'esos': 355,\n",
       " 'minuto': 356,\n",
       " 'bicicleta': 357,\n",
       " 'pasa': 358,\n",
       " 'lado': 359,\n",
       " 'quedo': 360,\n",
       " 'asi': 361,\n",
       " 'gatos': 362,\n",
       " 'o': 363,\n",
       " 'hermana': 364,\n",
       " 'familia': 365,\n",
       " 'respuesta': 366,\n",
       " 'ayer': 367,\n",
       " 'rico': 368,\n",
       " 'divertido': 369,\n",
       " 'extrano': 370,\n",
       " 'vuelve': 371,\n",
       " 'hacia': 372,\n",
       " 'persona': 373,\n",
       " 'llamo': 374,\n",
       " 'mala': 375,\n",
       " 'ninos': 376,\n",
       " 'sombrero': 377,\n",
       " 'saben': 378,\n",
       " 'hablando': 379,\n",
       " 'quieren': 380,\n",
       " 'ama': 381,\n",
       " 'ves': 382,\n",
       " 'cabeza': 383,\n",
       " 'debe': 384,\n",
       " 'volvio': 385,\n",
       " 'malo': 386,\n",
       " 'funciona': 387,\n",
       " 'aca': 388,\n",
       " 'da': 389,\n",
       " 'chico': 390,\n",
       " 'caja': 391,\n",
       " 'queda': 392,\n",
       " 'boca': 393,\n",
       " 'telefono': 394,\n",
       " 'vuelta': 395,\n",
       " 'paso': 396,\n",
       " 'cuenta': 397,\n",
       " 'felices': 398,\n",
       " 'empezo': 399,\n",
       " 'plan': 400,\n",
       " 'juego': 401,\n",
       " 'estabas': 402,\n",
       " 'comio': 403,\n",
       " 'esperando': 404,\n",
       " 'bajo': 405,\n",
       " 'estabamos': 406,\n",
       " 'vosotros': 407,\n",
       " 'abogado': 408,\n",
       " 'cara': 409,\n",
       " 'otro': 410,\n",
       " 'lleva': 411,\n",
       " 'mintiendo': 412,\n",
       " 'inteligente': 413,\n",
       " 'hiciste': 414,\n",
       " 'edad': 415,\n",
       " 'parar': 416,\n",
       " 'deberiamos': 417,\n",
       " 'verte': 418,\n",
       " 'tenis': 419,\n",
       " 'estuve': 420,\n",
       " 'importante': 421,\n",
       " 'esposa': 422,\n",
       " 'debes': 423,\n",
       " 'sal': 424,\n",
       " 'entiendo': 425,\n",
       " 'tome': 426,\n",
       " 'ocupada': 427,\n",
       " 'encontre': 428,\n",
       " 'amor': 429,\n",
       " 'encantan': 430,\n",
       " 'vuestro': 431,\n",
       " 'secreto': 432,\n",
       " 'suficiente': 433,\n",
       " 'palabra': 434,\n",
       " 'bailar': 435,\n",
       " 'sido': 436,\n",
       " 'manzana': 437,\n",
       " 'ni': 438,\n",
       " 'nuestra': 439,\n",
       " 'cierra': 440,\n",
       " 'venga': 441,\n",
       " 'cuidado': 442,\n",
       " 'come': 443,\n",
       " 'estare': 444,\n",
       " 'ciudad': 445,\n",
       " 'podes': 446,\n",
       " 'conoces': 447,\n",
       " 'lugar': 448,\n",
       " 'profesor': 449,\n",
       " 'habia': 450,\n",
       " 'ojala': 451,\n",
       " 'queres': 452,\n",
       " 'guerra': 453,\n",
       " 'aun': 454,\n",
       " 'camisa': 455,\n",
       " 'escucha': 456,\n",
       " 'gano': 457,\n",
       " 'acaso': 458,\n",
       " 'asiento': 459,\n",
       " 'dormido': 460,\n",
       " 'equivocado': 461,\n",
       " 'leyendo': 462,\n",
       " 'odia': 463,\n",
       " 'hermano': 464,\n",
       " 'afuera': 465,\n",
       " 'hijos': 466,\n",
       " 'toda': 467,\n",
       " 'sento': 468,\n",
       " 'despierto': 469,\n",
       " 'suyo': 470,\n",
       " 'salio': 471,\n",
       " 'carne': 472,\n",
       " 'ayudo': 473,\n",
       " 'levanto': 474,\n",
       " 'dice': 475,\n",
       " 'carta': 476,\n",
       " 'carro': 477,\n",
       " 'ambos': 478,\n",
       " 'pequeno': 479,\n",
       " 'bano': 480,\n",
       " 'cuarto': 481,\n",
       " 'llaves': 482,\n",
       " 'juntos': 483,\n",
       " 'estudiar': 484,\n",
       " 'parecia': 485,\n",
       " 'mesa': 486,\n",
       " 'parte': 487,\n",
       " 'correr': 488,\n",
       " 'deje': 489,\n",
       " 'hagas': 490,\n",
       " 'lejos': 491,\n",
       " 'termino': 492,\n",
       " 'tren': 493,\n",
       " 'importa': 494,\n",
       " 'dios': 495,\n",
       " 'hare': 496,\n",
       " 'grito': 497,\n",
       " 'ganar': 498,\n",
       " 'musica': 499,\n",
       " 'broma': 500,\n",
       " 'cancion': 501,\n",
       " 'digas': 502,\n",
       " 'tipo': 503,\n",
       " 'dolor': 504,\n",
       " 'sois': 505,\n",
       " 'conocen': 506,\n",
       " 'cuantos': 507,\n",
       " 'conoce': 508,\n",
       " 'tenes': 509,\n",
       " 'policia': 510,\n",
       " 'acaba': 511,\n",
       " 'seis': 512,\n",
       " 'suena': 513,\n",
       " 'sobre': 514,\n",
       " 'antes': 515,\n",
       " 'trabajando': 516,\n",
       " 'justo': 517,\n",
       " 'ello': 518,\n",
       " 'llame': 519,\n",
       " 'herido': 520,\n",
       " 'despues': 521,\n",
       " 'enojado': 522,\n",
       " 'tuyo': 523,\n",
       " 'dentro': 524,\n",
       " 'voz': 525,\n",
       " 'trampa': 526,\n",
       " 'tuvo': 527,\n",
       " 'equipo': 528,\n",
       " 'cocinar': 529,\n",
       " 'bolsa': 530,\n",
       " 'peligro': 531,\n",
       " 'chica': 532,\n",
       " 'canadiense': 533,\n",
       " 'amiga': 534,\n",
       " 'ropa': 535,\n",
       " 'serio': 536,\n",
       " 'gordo': 537,\n",
       " 'senti': 538,\n",
       " 'ten': 539,\n",
       " 'van': 540,\n",
       " 'caminar': 541,\n",
       " 'podeis': 542,\n",
       " 'teneis': 543,\n",
       " 'venido': 544,\n",
       " 'oido': 545,\n",
       " 'listos': 546,\n",
       " 'dias': 547,\n",
       " 'boligrafo': 548,\n",
       " 'reglas': 549,\n",
       " 'doctor': 550,\n",
       " 'llorando': 551,\n",
       " 'bromeando': 552,\n",
       " 'morir': 553,\n",
       " 'idiota': 554,\n",
       " 'error': 555,\n",
       " 'usar': 556,\n",
       " 'nina': 557,\n",
       " 'volver': 558,\n",
       " 'mucha': 559,\n",
       " 'padres': 560,\n",
       " 'largo': 561,\n",
       " 'despacio': 562,\n",
       " 'segundo': 563,\n",
       " 'olvide': 564,\n",
       " 'lloro': 565,\n",
       " 'echo': 566,\n",
       " 'paciente': 567,\n",
       " 'hombres': 568,\n",
       " 'amable': 569,\n",
       " 'sentia': 570,\n",
       " 'fin': 571,\n",
       " 'encontrar': 572,\n",
       " 'escucho': 573,\n",
       " 'pescado': 574,\n",
       " 'ingenuo': 575,\n",
       " 'casado': 576,\n",
       " 'aburrido': 577,\n",
       " 'saber': 578,\n",
       " 'alla': 579,\n",
       " 'quienes': 580,\n",
       " 'mujeres': 581,\n",
       " 'taxi': 582,\n",
       " 'tanto': 583,\n",
       " 'estudiando': 584,\n",
       " 'fumar': 585,\n",
       " 'dime': 586,\n",
       " 'autobus': 587,\n",
       " 'estudiante': 588,\n",
       " 'siguio': 589,\n",
       " 'deberias': 590,\n",
       " 'esas': 591,\n",
       " 'rompio': 592,\n",
       " 'pedi': 593,\n",
       " 'banco': 594,\n",
       " 'vaya': 595,\n",
       " 'perfecto': 596,\n",
       " 'toca': 597,\n",
       " 'pie': 598,\n",
       " 'genial': 599,\n",
       " 'cambio': 600,\n",
       " 'falta': 601,\n",
       " 'anda': 602,\n",
       " 'corriendo': 603,\n",
       " 'recuerdo': 604,\n",
       " 'dicho': 605,\n",
       " 'enfadado': 606,\n",
       " 'quieras': 607,\n",
       " 'roto': 608,\n",
       " 'manzanas': 609,\n",
       " 'sera': 610,\n",
       " 'ruido': 611,\n",
       " 'conducir': 612,\n",
       " 'japones': 613,\n",
       " 'verlo': 614,\n",
       " 'gustaria': 615,\n",
       " 'llamar': 616,\n",
       " 'compro': 617,\n",
       " 'sol': 618,\n",
       " 'seria': 619,\n",
       " 'tokio': 620,\n",
       " 'cosa': 621,\n",
       " 'camara': 622,\n",
       " 'manera': 623,\n",
       " 'mantente': 624,\n",
       " 'vista': 625,\n",
       " 'vayas': 626,\n",
       " 'entra': 627,\n",
       " 'prisa': 628,\n",
       " 'comi': 629,\n",
       " 'pago': 630,\n",
       " 'cansada': 631,\n",
       " 'caliente': 632,\n",
       " 'atras': 633,\n",
       " 'fueron': 634,\n",
       " 'contento': 635,\n",
       " 'llega': 636,\n",
       " 'dejar': 637,\n",
       " 'irte': 638,\n",
       " 'cocina': 639,\n",
       " 'ayudarte': 640,\n",
       " 'pregunto': 641,\n",
       " 'medico': 642,\n",
       " 'mirando': 643,\n",
       " 'brazo': 644,\n",
       " 'matar': 645,\n",
       " 'viste': 646,\n",
       " 'tener': 647,\n",
       " 'hermanos': 648,\n",
       " 'puesto': 649,\n",
       " 'adonde': 650,\n",
       " 'empezar': 651,\n",
       " 'ningun': 652,\n",
       " 'timido': 653,\n",
       " 'abre': 654,\n",
       " 'dejalo': 655,\n",
       " 'pan': 656,\n",
       " 'escribe': 657,\n",
       " 'normal': 658,\n",
       " 'correcto': 659,\n",
       " 'mama': 660,\n",
       " 'problemas': 661,\n",
       " 'sed': 662,\n",
       " 'posible': 663,\n",
       " 'pasado': 664,\n",
       " 'habeis': 665,\n",
       " 'perder': 666,\n",
       " 'volvere': 667,\n",
       " 'turno': 668,\n",
       " 'vayamos': 669,\n",
       " 'vere': 670,\n",
       " 'sintio': 671,\n",
       " 'paga': 672,\n",
       " 'vacia': 673,\n",
       " 'cena': 674,\n",
       " 'ganas': 675,\n",
       " 'lloviendo': 676,\n",
       " 'todas': 677,\n",
       " 'dano': 678,\n",
       " 'quisiera': 679,\n",
       " 'esperanza': 680,\n",
       " 'paris': 681,\n",
       " 'aquel': 682,\n",
       " 'cualquier': 683,\n",
       " 'dar': 684,\n",
       " 'solia': 685,\n",
       " 'papel': 686,\n",
       " 'adentro': 687,\n",
       " 'luego': 688,\n",
       " 'ire': 689,\n",
       " 'sabemos': 690,\n",
       " 'quede': 691,\n",
       " 'salvo': 692,\n",
       " 'enferma': 693,\n",
       " 'rojo': 694,\n",
       " 'baja': 695,\n",
       " 'coge': 696,\n",
       " 'tuya': 697,\n",
       " 'llegado': 698,\n",
       " 'empieza': 699,\n",
       " 'pregunta': 700,\n",
       " 'mentiroso': 701,\n",
       " 'blanco': 702,\n",
       " 'irse': 703,\n",
       " 'guapa': 704,\n",
       " 'huele': 705,\n",
       " 'bus': 706,\n",
       " 'nosotras': 707,\n",
       " 'noticias': 708,\n",
       " 'nieve': 709,\n",
       " 'pego': 710,\n",
       " 'rio': 711,\n",
       " 'valiente': 712,\n",
       " 'disparo': 713,\n",
       " 'tonto': 714,\n",
       " 'limitate': 715,\n",
       " 'corazon': 716,\n",
       " 'haces': 717,\n",
       " 'viven': 718,\n",
       " 'apenas': 719,\n",
       " 'fiesta': 720,\n",
       " 'intento': 721,\n",
       " 'agradable': 722,\n",
       " 'abajo': 723,\n",
       " 'adelante': 724,\n",
       " 'espere': 725,\n",
       " 'vuelto': 726,\n",
       " 'sonrio': 727,\n",
       " 'raro': 728,\n",
       " 'caso': 729,\n",
       " 'quedar': 730,\n",
       " 'detesto': 731,\n",
       " 'hielo': 732,\n",
       " 'hago': 733,\n",
       " 'canta': 734,\n",
       " 'hicimos': 735,\n",
       " 'haga': 736,\n",
       " 'conocemos': 737,\n",
       " 'comprar': 738,\n",
       " 'unos': 739,\n",
       " 'dulce': 740,\n",
       " 'engano': 741,\n",
       " 'jefe': 742,\n",
       " 'pude': 743,\n",
       " 'tomo': 744,\n",
       " 'llevo': 745,\n",
       " 'empleo': 746,\n",
       " 'toco': 747,\n",
       " 'luz': 748,\n",
       " 'arma': 749,\n",
       " 'caballo': 750,\n",
       " 'dejes': 751,\n",
       " 'pescar': 752,\n",
       " 'tio': 753,\n",
       " 'menudo': 754,\n",
       " 'muchos': 755,\n",
       " 'verano': 756,\n",
       " 'llegar': 757,\n",
       " 'haber': 758,\n",
       " 'dientes': 759,\n",
       " 'consejo': 760,\n",
       " 'llover': 761,\n",
       " 'pidio': 762,\n",
       " 'foto': 763,\n",
       " 'torta': 764,\n",
       " 'nuestros': 765,\n",
       " 'hola': 766,\n",
       " 'vemos': 767,\n",
       " 'ponte': 768,\n",
       " 'intenta': 769,\n",
       " 'buenas': 770,\n",
       " 'terminado': 771,\n",
       " 'pasar': 772,\n",
       " 'sientate': 773,\n",
       " 'venid': 774,\n",
       " 'lee': 775,\n",
       " 'mando': 776,\n",
       " 'gratis': 777,\n",
       " 'hicieron': 778,\n",
       " 'miro': 779,\n",
       " 'debemos': 780,\n",
       " 'pero': 781,\n",
       " 'preparado': 782,\n",
       " 'nervioso': 783,\n",
       " 'vivir': 784,\n",
       " 'piensa': 785,\n",
       " 'colegio': 786,\n",
       " 'corto': 787,\n",
       " 'entro': 788,\n",
       " 'papa': 789,\n",
       " 'pajaro': 790,\n",
       " 'beso': 791,\n",
       " 'cuerda': 792,\n",
       " 'futbol': 793,\n",
       " 'caballos': 794,\n",
       " 'prefiero': 795,\n",
       " 'viendo': 796,\n",
       " 'escuchando': 797,\n",
       " 'japon': 798,\n",
       " 'eran': 799,\n",
       " 'adora': 800,\n",
       " 'escribio': 801,\n",
       " 'muerte': 802,\n",
       " 'enemigo': 803,\n",
       " 'confiar': 804,\n",
       " 'ventana': 805,\n",
       " 'fuego': 806,\n",
       " 'levanta': 807,\n",
       " 'preguntale': 808,\n",
       " 'hable': 809,\n",
       " 'lleno': 810,\n",
       " 'pajaros': 811,\n",
       " 'irnos': 812,\n",
       " 'adoro': 813,\n",
       " 'muriendo': 814,\n",
       " 'diez': 815,\n",
       " 'mire': 816,\n",
       " 'cualquiera': 817,\n",
       " 'agrada': 818,\n",
       " 'nueva': 819,\n",
       " 'contacto': 820,\n",
       " 'aire': 821,\n",
       " 'sopa': 822,\n",
       " 'atrapado': 823,\n",
       " 'cerro': 824,\n",
       " 'mayor': 825,\n",
       " 'pena': 826,\n",
       " 'paciencia': 827,\n",
       " 'ayudarme': 828,\n",
       " 'gustaba': 829,\n",
       " 'negro': 830,\n",
       " 'alta': 831,\n",
       " 'algunos': 832,\n",
       " 'peso': 833,\n",
       " 'dale': 834,\n",
       " 'nariz': 835,\n",
       " 'pienso': 836,\n",
       " 'respeto': 837,\n",
       " 'dan': 838,\n",
       " 'toques': 839,\n",
       " 'taza': 840,\n",
       " 'camion': 841,\n",
       " 'punto': 842,\n",
       " 'almuerzo': 843,\n",
       " 'dedo': 844,\n",
       " 'lapiz': 845,\n",
       " 'totalmente': 846,\n",
       " 'acerca': 847,\n",
       " 'corre': 848,\n",
       " 'quieto': 849,\n",
       " 'calvo': 850,\n",
       " 'debil': 851,\n",
       " 'cayo': 852,\n",
       " 'veia': 853,\n",
       " 'silencio': 854,\n",
       " 'arriba': 855,\n",
       " 'entonces': 856,\n",
       " 'cantando': 857,\n",
       " 'heroe': 858,\n",
       " 'soltero': 859,\n",
       " 'real': 860,\n",
       " 'ojo': 861,\n",
       " 'intentarlo': 862,\n",
       " 'verme': 863,\n",
       " 'vengo': 864,\n",
       " 'chicos': 865,\n",
       " 'azul': 866,\n",
       " 'gustas': 867,\n",
       " 'alguna': 868,\n",
       " 'necesitaba': 869,\n",
       " 'veces': 870,\n",
       " 'durmiendo': 871,\n",
       " 'monton': 872,\n",
       " 'grandes': 873,\n",
       " 'mios': 874,\n",
       " 'tarta': 875,\n",
       " 'descansar': 876,\n",
       " 'atencion': 877,\n",
       " 'claro': 878,\n",
       " 'robo': 879,\n",
       " 'encontrado': 880,\n",
       " 'escribir': 881,\n",
       " 'ley': 882,\n",
       " 'vendra': 883,\n",
       " 'treinta': 884,\n",
       " 'simplemente': 885,\n",
       " 'cinco': 886,\n",
       " 'gafas': 887,\n",
       " 'tele': 888,\n",
       " 'abierta': 889,\n",
       " 'peligroso': 890,\n",
       " 'mensaje': 891,\n",
       " 'cartas': 892,\n",
       " 'orgulloso': 893,\n",
       " 'abrir': 894,\n",
       " 'misma': 895,\n",
       " 'alegro': 896,\n",
       " 'continua': 897,\n",
       " 'ganado': 898,\n",
       " 'corrio': 899,\n",
       " 'ninguna': 900,\n",
       " 'calma': 901,\n",
       " 'ayudame': 902,\n",
       " 'mintio': 903,\n",
       " 'volar': 904,\n",
       " 'oscuro': 905,\n",
       " 'vimos': 906,\n",
       " 'hables': 907,\n",
       " 'asustado': 908,\n",
       " 'loca': 909,\n",
       " 'termina': 910,\n",
       " 'golf': 911,\n",
       " 'dudas': 912,\n",
       " 'confundido': 913,\n",
       " 'pierna': 914,\n",
       " 'abra': 915,\n",
       " 'necesitan': 916,\n",
       " 'gracioso': 917,\n",
       " 'vine': 918,\n",
       " 'primavera': 919,\n",
       " 'detras': 920,\n",
       " 'peor': 921,\n",
       " 'regalo': 922,\n",
       " 'espalda': 923,\n",
       " 'simple': 924,\n",
       " 'izquierda': 925,\n",
       " 'fuimos': 926,\n",
       " 'cuchillo': 927,\n",
       " 'traeme': 928,\n",
       " 'cambiado': 929,\n",
       " 'decision': 930,\n",
       " 'corbata': 931,\n",
       " 'crees': 932,\n",
       " 'abrio': 933,\n",
       " 'piano': 934,\n",
       " 'pasando': 935,\n",
       " 'paraguas': 936,\n",
       " 'piernas': 937,\n",
       " 'viajar': 938,\n",
       " 'completamente': 939,\n",
       " 'pelicula': 940,\n",
       " 'larga': 941,\n",
       " 'podrias': 942,\n",
       " 'creer': 943,\n",
       " 'caro': 944,\n",
       " 'abrigo': 945,\n",
       " 'hablas': 946,\n",
       " 'breve': 947,\n",
       " 'uso': 948,\n",
       " 'pagare': 949,\n",
       " 'estupendo': 950,\n",
       " 'toalla': 951,\n",
       " 'golpeo': 952,\n",
       " 'camina': 953,\n",
       " 'cruel': 954,\n",
       " 'mordio': 955,\n",
       " 'ocupados': 956,\n",
       " 'muneca': 957,\n",
       " 'deseo': 958,\n",
       " 'hermosa': 959,\n",
       " 'celoso': 960,\n",
       " 'saberlo': 961,\n",
       " 'canto': 962,\n",
       " 'bienvenido': 963,\n",
       " 'estudio': 964,\n",
       " 'culpable': 965,\n",
       " 'tenido': 966,\n",
       " 'bolso': 967,\n",
       " 'avion': 968,\n",
       " 'hambriento': 969,\n",
       " 'siente': 970,\n",
       " 'paz': 971,\n",
       " 'numero': 972,\n",
       " 'unas': 973,\n",
       " 'pelota': 974,\n",
       " 'riendo': 975,\n",
       " 'estara': 976,\n",
       " 'muertos': 977,\n",
       " 'trata': 978,\n",
       " 'viaje': 979,\n",
       " 'preocupado': 980,\n",
       " 'radio': 981,\n",
       " 'oficina': 982,\n",
       " 'lago': 983,\n",
       " 'entiende': 984,\n",
       " 'vives': 985,\n",
       " 'nacio': 986,\n",
       " 'siendo': 987,\n",
       " 'oportunidad': 988,\n",
       " 'escuche': 989,\n",
       " 'llamame': 990,\n",
       " 'entre': 991,\n",
       " 'gorda': 992,\n",
       " 'prueba': 993,\n",
       " 'profundo': 994,\n",
       " 'perfectamente': 995,\n",
       " 'llena': 996,\n",
       " 'pobre': 997,\n",
       " 'gane': 998,\n",
       " 'confia': 999,\n",
       " 'vosotras': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_lang.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 16), (64, 11)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 16)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 11)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz # 64\n",
    "    self.enc_units = enc_units # 24000 // 64 = 375\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim) # (9414, 256)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units, # 1024\n",
    "                                   return_sequences=True, \n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9414"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_inp_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, # 9414\n",
    "                  embedding_dim, # 256\n",
    "                  units, # 1024\n",
    "                  BATCH_SIZE # 24000\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 16]), TensorShape([64, 11]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 16])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 11])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 1024])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプル入力\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 16, 1024]), TensorShape([64, 1024]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_output.shape, sample_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # hidden shape == (batch_size, hidden size)\n",
    "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # スコアを計算するためにこのように加算を実行する\n",
    "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # スコアを self.V に適用するために最後の軸は 1 となる\n",
    "    # self.V に適用する前のテンソルの shape は  (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "    # attention_weights の shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector の合計後の shape == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights[0].numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_sum(attention_weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # アテンションのため\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # enc_output の shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(hidden, # The hidden vector of the decodr. \n",
    "                                                               # This is the query　of calculating attentions. \n",
    "                                                       enc_output) # You need enocder outpus as keys\n",
    "    \n",
    "    # Attention mechanism calculates correlations of the query and keys, and the scores are regularized \n",
    "    # with a softmax function.\n",
    "\n",
    "    # 埋め込み層を通過したあとの x の shape  == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # 結合後の x の shape == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # 結合したベクトルを GRU 層に渡す\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4935"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_tar_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9414"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_inp_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n",
      "(64, 16)\n",
      "(64, 11)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    print(inp.shape)\n",
    "    print(targ.shape)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, \n",
    "                                           dec_hidden, \n",
    "                                           enc_output) # You need encoder outputs to calculate attentions. \n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
