{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T01:25:16.887127Z",
     "iopub.status.busy": "2020-09-27T01:25:16.886350Z",
     "iopub.status.idle": "2020-09-27T01:25:23.514378Z",
     "shell.execute_reply": "2020-09-27T01:25:23.513828Z"
    },
    "id": "JjJJyJTZYebt"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import torch.optim as optim\n",
    "\n",
    "from bpemb import BPEmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "bpemb_ja = BPEmb(lang='ja', vs=vocab_size, dim=100)\n",
    "bpemb_en = BPEmb(lang='en', vs=vocab_size, dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"./datasets/jpn.txt\"\n",
    "\n",
    "lines = io.open(path_to_file, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "temp_list = []\n",
    "corpus = []\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    temp_list =  lines[i].split('\\t')[:-1]\n",
    "    corpus.append(temp_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40\n",
    "\n",
    "en, ja = np.array(corpus).T\n",
    "\n",
    "en_encoded = []\n",
    "ja_encoded = []\n",
    "\n",
    "cnt_en = 0\n",
    "cnt_ja = 0\n",
    "\n",
    "for i in range(len(en)):\n",
    "    en_encoded_temp = bpemb_en.encode_ids(en[i])\n",
    "    ja_encoded_temp = bpemb_ja.encode_ids(ja[i])\n",
    "    \n",
    "    if (len(en_encoded_temp)<=MAX_LENGTH) and (len(ja_encoded_temp)<=MAX_LENGTH):\n",
    "        en_encoded.append([vocab_size] + en_encoded_temp + [vocab_size + 1])\n",
    "        ja_encoded.append([vocab_size] + ja_encoded_temp + [vocab_size + 1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_padded = tf.keras.preprocessing.sequence.pad_sequences(en_encoded, padding='post')\n",
    "ja_padded = tf.keras.preprocessing.sequence.pad_sequences(ja_encoded, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_size = 10000\n",
    "vocab_inp_size = vocab_size + 2\n",
    "vocab_tar_size = vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "import glob\n",
    "class EN_JA_Corpus(torch.utils.data.Dataset):\n",
    "    def __init__(self,  corpus_en, corpus_ja, transforms=None,):\n",
    "        \n",
    "        self.corpus_en = corpus_en\n",
    "        self.corpus_ja = corpus_ja\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        source = torch.tensor(self.corpus_en[idx]).to(dtype=torch.long)\n",
    "        target = torch.tensor(self.corpus_ja[idx]).to(dtype=torch.long)\n",
    "        \n",
    "\n",
    "       # if self.transforms is not None:\n",
    "         #   img, target = self.transforms(img, target)\n",
    "\n",
    "        return source, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.corpus_en.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        # during training, randomly flip the training images\n",
    "        # and ground-truth for data augmentation\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EN_JA_Corpus(en_padded, ja_padded)\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T01:27:45.616318Z",
     "iopub.status.busy": "2020-09-27T01:27:45.615771Z",
     "iopub.status.idle": "2020-09-27T01:27:45.617969Z",
     "shell.execute_reply": "2020-09-27T01:27:45.617431Z"
    },
    "id": "bcRp7VcQ5m6g"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T01:27:45.840615Z",
     "iopub.status.busy": "2020-09-27T01:27:45.840062Z",
     "iopub.status.idle": "2020-09-27T01:27:45.841757Z",
     "shell.execute_reply": "2020-09-27T01:27:45.842107Z"
    },
    "id": "WhIOZjMNKujn"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T01:27:45.847530Z",
     "iopub.status.busy": "2020-09-27T01:27:45.846912Z",
     "iopub.status.idle": "2020-09-27T01:27:45.848626Z",
     "shell.execute_reply": "2020-09-27T01:27:45.849030Z"
    },
    "id": "1Rz82wEs5biZ"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return torch.Tensor(pos_encoding)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T01:27:46.374095Z",
     "iopub.status.busy": "2020-09-27T01:27:46.373573Z",
     "iopub.status.idle": "2020-09-27T01:27:46.375314Z",
     "shell.execute_reply": "2020-09-27T01:27:46.375664Z"
    },
    "id": "U2i8-e1s8ti9"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "  seq = torch.eq(seq, 0).to(dtype=torch.float)\n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return (torch.from_numpy(subsequent_mask) == 1).to(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T01:27:46.404037Z",
     "iopub.status.busy": "2020-09-27T01:27:46.403506Z",
     "iopub.status.idle": "2020-09-27T01:27:46.405697Z",
     "shell.execute_reply": "2020-09-27T01:27:46.405260Z"
    },
    "id": "LazzUq3bJ5SH"
   },
   "outputs": [],
   "source": [
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "    \n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = torch.matmul(q, k.transpose(len(k.shape)-2, len(k.shape)-1))  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "    # scale matmul_qk\n",
    "    #print(k.shape)\n",
    "    dk = torch.Tensor([k.shape[-1]])\n",
    "    #print(dk)\n",
    "    scaled_attention_logits = matmul_qk / torch.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    softmax = nn.Softmax(dim=-1)\n",
    "    attention_weights = softmax(scaled_attention_logits).to(dtype=torch.float)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = torch.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "  temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "  print ('Attention weights are:')\n",
    "  print (temp_attn)\n",
    "  print ('Output is:')\n",
    "  print (temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tensor([[8.4333e-26, 1.0000e+00, 8.4333e-26, 8.4333e-26]])\n",
      "Output is:\n",
      "tensor([[1.0000e+01, 9.2766e-25]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = torch.Tensor([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]])  # (4, 3)\n",
    "\n",
    "temp_v = torch.Tensor([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]])  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "temp_q = torch.Tensor([[0, 10, 0]])  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T01:27:46.617545Z",
     "iopub.status.busy": "2020-09-27T01:27:46.616460Z",
     "iopub.status.idle": "2020-09-27T01:27:46.619254Z",
     "shell.execute_reply": "2020-09-27T01:27:46.619670Z"
    },
    "id": "BSV3PPKsYecw"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "class MultiHeadAttention(nn.Module):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "    \n",
    "    assert d_model % self.num_heads == 0\n",
    "    \n",
    "    self.depth = d_model // self.num_heads\n",
    "    \n",
    "    self.wq = nn.Linear(in_features=d_model , out_features=d_model)\n",
    "    self.wk = nn.Linear(in_features=d_model , out_features=d_model)\n",
    "    self.wv = nn.Linear(in_features=d_model , out_features=d_model)\n",
    "        \n",
    "    self.dense = nn.Linear(in_features=d_model, out_features=d_model)\n",
    "\n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = torch.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return x.permute([0, 2, 1, 3])\n",
    "    \n",
    "  def forward(self, v, k, q, mask=None):\n",
    "    batch_size = q.shape[0]\n",
    "    \n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "    \n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "    \n",
    "    scaled_attention = scaled_attention.permute([0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = torch.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 512])\n",
      "tensor([[[   1,    2,    3,  ...,  510,  511,  512],\n",
      "         [ 513,  514,  515,  ..., 1022, 1023, 1024],\n",
      "         [1025, 1026, 1027,  ..., 1534, 1535, 1536],\n",
      "         ...,\n",
      "         [3073, 3074, 3075,  ..., 3582, 3583, 3584],\n",
      "         [3585, 3586, 3587,  ..., 4094, 4095, 4096],\n",
      "         [4097, 4098, 4099,  ..., 4606, 4607, 4608]]])\n"
     ]
    }
   ],
   "source": [
    "sample_query = np.arange(1*9*512).reshape((1, 9, 512)) + 1\n",
    "sample_query = torch.tensor(sample_query)\n",
    "print(sample_query.shape)\n",
    "print(sample_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 8, 64])\n",
      "tensor([[[[   1,    2,    3,  ...,   62,   63,   64],\n",
      "          [  65,   66,   67,  ...,  126,  127,  128],\n",
      "          [ 129,  130,  131,  ...,  190,  191,  192],\n",
      "          ...,\n",
      "          [ 321,  322,  323,  ...,  382,  383,  384],\n",
      "          [ 385,  386,  387,  ...,  446,  447,  448],\n",
      "          [ 449,  450,  451,  ...,  510,  511,  512]],\n",
      "\n",
      "         [[ 513,  514,  515,  ...,  574,  575,  576],\n",
      "          [ 577,  578,  579,  ...,  638,  639,  640],\n",
      "          [ 641,  642,  643,  ...,  702,  703,  704],\n",
      "          ...,\n",
      "          [ 833,  834,  835,  ...,  894,  895,  896],\n",
      "          [ 897,  898,  899,  ...,  958,  959,  960],\n",
      "          [ 961,  962,  963,  ..., 1022, 1023, 1024]],\n",
      "\n",
      "         [[1025, 1026, 1027,  ..., 1086, 1087, 1088],\n",
      "          [1089, 1090, 1091,  ..., 1150, 1151, 1152],\n",
      "          [1153, 1154, 1155,  ..., 1214, 1215, 1216],\n",
      "          ...,\n",
      "          [1345, 1346, 1347,  ..., 1406, 1407, 1408],\n",
      "          [1409, 1410, 1411,  ..., 1470, 1471, 1472],\n",
      "          [1473, 1474, 1475,  ..., 1534, 1535, 1536]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3073, 3074, 3075,  ..., 3134, 3135, 3136],\n",
      "          [3137, 3138, 3139,  ..., 3198, 3199, 3200],\n",
      "          [3201, 3202, 3203,  ..., 3262, 3263, 3264],\n",
      "          ...,\n",
      "          [3393, 3394, 3395,  ..., 3454, 3455, 3456],\n",
      "          [3457, 3458, 3459,  ..., 3518, 3519, 3520],\n",
      "          [3521, 3522, 3523,  ..., 3582, 3583, 3584]],\n",
      "\n",
      "         [[3585, 3586, 3587,  ..., 3646, 3647, 3648],\n",
      "          [3649, 3650, 3651,  ..., 3710, 3711, 3712],\n",
      "          [3713, 3714, 3715,  ..., 3774, 3775, 3776],\n",
      "          ...,\n",
      "          [3905, 3906, 3907,  ..., 3966, 3967, 3968],\n",
      "          [3969, 3970, 3971,  ..., 4030, 4031, 4032],\n",
      "          [4033, 4034, 4035,  ..., 4094, 4095, 4096]],\n",
      "\n",
      "         [[4097, 4098, 4099,  ..., 4158, 4159, 4160],\n",
      "          [4161, 4162, 4163,  ..., 4222, 4223, 4224],\n",
      "          [4225, 4226, 4227,  ..., 4286, 4287, 4288],\n",
      "          ...,\n",
      "          [4417, 4418, 4419,  ..., 4478, 4479, 4480],\n",
      "          [4481, 4482, 4483,  ..., 4542, 4543, 4544],\n",
      "          [4545, 4546, 4547,  ..., 4606, 4607, 4608]]]])\n"
     ]
    }
   ],
   "source": [
    "sample_query = torch.reshape(sample_query, (1, 9, 8, 64))\n",
    "print(sample_query.shape)\n",
    "print(sample_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 9, 64])\n",
      "tensor([[[[   1,    2,    3,  ...,   62,   63,   64],\n",
      "          [ 513,  514,  515,  ...,  574,  575,  576],\n",
      "          [1025, 1026, 1027,  ..., 1086, 1087, 1088],\n",
      "          ...,\n",
      "          [3073, 3074, 3075,  ..., 3134, 3135, 3136],\n",
      "          [3585, 3586, 3587,  ..., 3646, 3647, 3648],\n",
      "          [4097, 4098, 4099,  ..., 4158, 4159, 4160]],\n",
      "\n",
      "         [[  65,   66,   67,  ...,  126,  127,  128],\n",
      "          [ 577,  578,  579,  ...,  638,  639,  640],\n",
      "          [1089, 1090, 1091,  ..., 1150, 1151, 1152],\n",
      "          ...,\n",
      "          [3137, 3138, 3139,  ..., 3198, 3199, 3200],\n",
      "          [3649, 3650, 3651,  ..., 3710, 3711, 3712],\n",
      "          [4161, 4162, 4163,  ..., 4222, 4223, 4224]],\n",
      "\n",
      "         [[ 129,  130,  131,  ...,  190,  191,  192],\n",
      "          [ 641,  642,  643,  ...,  702,  703,  704],\n",
      "          [1153, 1154, 1155,  ..., 1214, 1215, 1216],\n",
      "          ...,\n",
      "          [3201, 3202, 3203,  ..., 3262, 3263, 3264],\n",
      "          [3713, 3714, 3715,  ..., 3774, 3775, 3776],\n",
      "          [4225, 4226, 4227,  ..., 4286, 4287, 4288]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 321,  322,  323,  ...,  382,  383,  384],\n",
      "          [ 833,  834,  835,  ...,  894,  895,  896],\n",
      "          [1345, 1346, 1347,  ..., 1406, 1407, 1408],\n",
      "          ...,\n",
      "          [3393, 3394, 3395,  ..., 3454, 3455, 3456],\n",
      "          [3905, 3906, 3907,  ..., 3966, 3967, 3968],\n",
      "          [4417, 4418, 4419,  ..., 4478, 4479, 4480]],\n",
      "\n",
      "         [[ 385,  386,  387,  ...,  446,  447,  448],\n",
      "          [ 897,  898,  899,  ...,  958,  959,  960],\n",
      "          [1409, 1410, 1411,  ..., 1470, 1471, 1472],\n",
      "          ...,\n",
      "          [3457, 3458, 3459,  ..., 3518, 3519, 3520],\n",
      "          [3969, 3970, 3971,  ..., 4030, 4031, 4032],\n",
      "          [4481, 4482, 4483,  ..., 4542, 4543, 4544]],\n",
      "\n",
      "         [[ 449,  450,  451,  ...,  510,  511,  512],\n",
      "          [ 961,  962,  963,  ..., 1022, 1023, 1024],\n",
      "          [1473, 1474, 1475,  ..., 1534, 1535, 1536],\n",
      "          ...,\n",
      "          [3521, 3522, 3523,  ..., 3582, 3583, 3584],\n",
      "          [4033, 4034, 4035,  ..., 4094, 4095, 4096],\n",
      "          [4545, 4546, 4547,  ..., 4606, 4607, 4608]]]])\n"
     ]
    }
   ],
   "source": [
    "sample_query = sample_query.permute([0, 2, 1, 3])\n",
    "print(sample_query.shape)\n",
    "print(sample_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 60, 512]), torch.Size([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = torch.ones((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, y, y)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T01:27:46.659573Z",
     "iopub.status.busy": "2020-09-27T01:27:46.658915Z",
     "iopub.status.idle": "2020-09-27T01:27:46.661172Z",
     "shell.execute_reply": "2020-09-27T01:27:46.660671Z"
    },
    "id": "ET7xLt0yCT6Z"
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return nn.Sequential(\n",
    "      nn.Linear(in_features=d_model, out_features=dff),  # (batch_size, seq_len, dff)\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(in_features=dff, out_features=d_model)  # (batch_size, seq_len, d_model)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T01:27:46.699328Z",
     "iopub.status.busy": "2020-09-27T01:27:46.698640Z",
     "iopub.status.idle": "2020-09-27T01:27:46.700613Z",
     "shell.execute_reply": "2020-09-27T01:27:46.700958Z"
    },
    "id": "ncyS-Ms3i2x_"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "    self.layernorm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "    \n",
    "    self.dropout1 = nn.Dropout(p=rate)\n",
    "    self.dropout2 = nn.Dropout(p=rate)\n",
    "    \n",
    "  def forward(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 43, 512])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    torch.ones((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T01:27:46.765993Z",
     "iopub.status.busy": "2020-09-27T01:27:46.765450Z",
     "iopub.status.idle": "2020-09-27T01:27:46.767350Z",
     "shell.execute_reply": "2020-09-27T01:27:46.766844Z"
    },
    "id": "9SoX0-vd1hue"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    " \n",
    "    self.layernorm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "    self.layernorm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "    self.layernorm3 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "    \n",
    "    self.dropout1 = nn.Dropout(p=rate)\n",
    "    self.dropout2 = nn.Dropout(p=rate)\n",
    "    self.dropout3 = nn.Dropout(p=rate)\n",
    "    \n",
    "    \n",
    "  def forward(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "    \n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 50, 512])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _,_ = sample_decoder_layer(\n",
    "    torch.ones((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T01:27:46.839967Z",
     "iopub.status.busy": "2020-09-27T01:27:46.839333Z",
     "iopub.status.idle": "2020-09-27T01:27:46.841099Z",
     "shell.execute_reply": "2020-09-27T01:27:46.841443Z"
    },
    "id": "jpEox7gJ8FCI"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    #self.pre_embedding = tf.keras.layers.Dense(input_vocab_size, 100)\n",
    "    \n",
    "    self.embedding = nn.Embedding(num_embeddings=input_vocab_size, embedding_dim=d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                            self.d_model)\n",
    "    \n",
    "    \n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "  \n",
    "    self.dropout = nn.Dropout(p=rate)\n",
    "        \n",
    "  def forward(self, x, training, mask):\n",
    "\n",
    "    seq_len = x.shape[1]\n",
    "    \n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)    \n",
    "    x *= torch.sqrt(torch.Tensor([self.d_model]))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x)    \n",
    "    \n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "    return x  # (batch_size, input_seq_len, d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 62, 512])\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "#temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_input = np.random.randint(8500, size=(64, 62))\n",
    "temp_input = torch.tensor(temp_input)\n",
    "#temp_input = torch.rand((64, 62))\n",
    "sample_encoder_output = sample_encoder(temp_input,  training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T01:27:47.163368Z",
     "iopub.status.busy": "2020-09-27T01:27:47.162774Z",
     "iopub.status.idle": "2020-09-27T01:27:47.164447Z",
     "shell.execute_reply": "2020-09-27T01:27:47.164782Z"
    },
    "id": "d5_d5-PLQXwY"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    #self.pre_embedding = tf.keras.layers.Dense(target_vocab_size, 100)\n",
    "    \n",
    "    self.embedding = nn.Embedding(num_embeddings=target_vocab_size, embedding_dim=d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "    \n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = nn.Dropout(p=rate)\n",
    "    \n",
    "  def forward(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "    #print(\"The shape of 'x' is \" + str(tf.shape(x)))\n",
    "\n",
    "    seq_len = x.shape[1]\n",
    "    #print(\"'seq_len' is \" + str(seq_len))\n",
    "    \n",
    "    \n",
    "    #x = self.pre_embedding(x)\n",
    "\n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= torch.sqrt(torch.Tensor([self.d_model]))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "      \n",
    "    \n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    #print(\"The shape of 'x' is \" + str(tf.shape(x)))\n",
    "    \n",
    "    return x, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 26, 512])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "#temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_input = np.random.randint(8000, size=(64, 26))\n",
    "temp_input = torch.tensor(temp_input)\n",
    "#temp_input = torch.rand((64, 62))\n",
    "\n",
    "output, _ = sample_decoder(temp_input, \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False,\n",
    "                              look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 62])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T01:27:47.394726Z",
     "iopub.status.busy": "2020-09-27T01:27:47.394164Z",
     "iopub.status.idle": "2020-09-27T01:27:47.395964Z",
     "shell.execute_reply": "2020-09-27T01:27:47.396326Z"
    },
    "id": "PED3bIpOYkBu"
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = nn.Linear(in_features=d_model , out_features=target_vocab_size)\n",
    "    \n",
    "  def forward(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    #print('enc_output')\n",
    "    #print(enc_output)\n",
    "    \n",
    "    #dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "    \n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 36, 8000])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000, \n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "#temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
    "#temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "temp_input = np.random.randint(8500, size=(64, 38))\n",
    "temp_input = torch.tensor(temp_input)\n",
    "\n",
    "temp_target = np.random.randint(8000, size=(64, 36))\n",
    "temp_target = torch.tensor(temp_target)\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T01:27:47.931823Z",
     "iopub.status.busy": "2020-09-27T01:27:47.931263Z",
     "iopub.status.idle": "2020-09-27T01:27:47.933193Z",
     "shell.execute_reply": "2020-09-27T01:27:47.933543Z"
    },
    "id": "iYQdOO1axwEI"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = d_model\n",
    "    self.d_model = torch.Tensor([self.d_model])\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    arg1 = torch.rsqrt(torch.Tensor(step))\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return torch.rsqrt(self.d_model) * torch.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VvWZ///XRUJCQiCQhS1sYVODC2qktlqtUhVbK06rLXY6X9vaccbKt7a20+J3ZpzWqb9vnbZfW6vWcaqW2gWtdqHWfalVqyAogqBAFpaw5Q5CIIEQkly/P84J3sQsd5aTO8v7+XjkwbnP8jnXfSfkyud8Puc65u6IiIj0tCHJDkBERAYmJRgREYmEEoyIiERCCUZERCKhBCMiIpFQghERkUgowYiISCSUYEREJBJKMCIiEonUZAeQTHl5eT516tRkhyEi0q+sWrWqyt3zO9pvUCeYqVOnsnLlymSHISLSr5jZlkT20yUyERGJhBKMiIhEQglGREQioQQjIiKRiDTBmNl8M9tgZiVmtriV7elm9mC4fbmZTY3bdmO4foOZXdRRm2b2opmtDr92mNkfonxvIiLSvshmkZlZCnAncAFQAbxmZsvcfX3cblcDe919hpktBG4FPmNmRcBCYDYwAXjGzGaFx7Taprt/OO7cjwB/jOq9iYhIx6LswcwFSty9zN3rgaXAghb7LACWhMsPA/PMzML1S939sLuXAyVhex22aWYjgfMB9WBERJIoygRTAGyLe10Rrmt1H3dvAKqB3HaOTaTNy4Bn3X1/N+Pvc+obmvjNiq0caWxKdigiIh0aiIP8VwK/aWujmV1jZivNbGUsFuvFsLrvt6u2cePv1nLvS+XJDkVEpENRJpjtwKS41xPDda3uY2apQDawp51j223TzPIILqP9ua2g3P0edy929+L8/A4rHfQp79bUA/BySVWSIxER6ViUCeY1YKaZFZpZGsGg/bIW+ywDrgqXLweec3cP1y8MZ5kVAjOBFQm0eTnwqLvXRfaukqh8Ty0Ar21+l4P1DUmORkSkfZElmHBMZRHwJPA28JC7rzOzm83s0nC3e4FcMysBbgAWh8euAx4C1gNPANe5e2NbbcaddiHtXB7r70pjtZhB3ZEm/rKhf13eE5HBx4IOw+BUXFzs/aXYpbtz8nee4pKTJ/Dkul2cNSOPn1x5arLDEpFByMxWuXtxR/sN6mrK/Ums5jAH6hqYNTYLGMuy1TuoO9LIsKEpyQ5NRKRVA3EW2YBUFgvGX6blZzH/xPHU1jfy4iYN9otI36UE0080J5jp+cP50PRcRmUO5U9v7khyVCIibVOC6SdKYzUMGzqECdkZDE0ZwsdPGs9T63dRc1izyUSkb1KC6SfKYjUU5mUxZIgB8MnTCqg70sSTb+1KcmQiIq1TguknSmO1TMsffvT1aZNHMzknk9+/0fLeVRGRvkEJph843NBIxd6DTM97L8GYGZedWsDLpVXs3j8g7ysVkX5OCaYf2LLnIE0O08dkHbP+704twB3+uFq9GBHpe5Rg+oHSyhoApuUdm2AK84YzZ9IoHlm1ncF8w6yI9E1KMP1AWVXzPTDD37ftiuKJbNh9gNXb9vV2WCIi7VKC6QdKK2sYN3IYw9PfX3hhwZwCMtNS+PXyrUmITESkbUow/UBpVW2rvReArPRUFsyZwJ/W7GB/3ZFejkxEpG1KMH2cu1NWWcP0/Kw29/ns3CnUHWniD5qyLCJ9iBJMHxerOcyBww1t9mAATpqYzYkFI/n18q0a7BeRPkMJpo97rwZZ2z0YgCvnTuadXQd4fasG+0Wkb1CC6eNKY+EU5XZ6MACXzSlgxLBU7nu5vDfCEhHpkBJMH1cWqz1a5LI9w9NTuXLuZJ54axcVew/2UnQiIm1TgunjSlsUuWzPVR+aCsCSv22ONigRkQQowfRxZbG2pyi3VDAqg4tPHMfSFdtUxl9Ekk4Jpg+rOxIWuexggD/e1WcXcuBwA79duS3CyEREOhZpgjGz+Wa2wcxKzGxxK9vTzezBcPtyM5sat+3GcP0GM7uoozYtcIuZbTSzt83sK1G+t95wtMhlgj0YgFMnj+a0yaO496VyjjQ2RRidiEj7IkswZpYC3AlcDBQBV5pZUYvdrgb2uvsM4Dbg1vDYImAhMBuYD9xlZikdtPl5YBJwvLufACyN6r31lrJwBllnejAAX/7IDCr2HuKPq/VIZRFJnih7MHOBEncvc/d6gl/4C1rsswBYEi4/DMwzMwvXL3X3w+5eDpSE7bXX5rXAze7eBODulRG+t17RPEW5MC/xHgzAvBPGcML4kdz1fAmNTbrxUkSSI8oEUwDEDwRUhOta3cfdG4BqILedY9trczrwGTNbaWaPm9nM1oIys2vCfVbGYrEuvbHeUharbbPIZXvMjP99/gzKqmr589qdEUUnItK+gTTInw7UuXsx8D/Afa3t5O73uHuxuxfn5+f3aoCdVRqrYfqYzvVems2fPY6ZY7K447lNNKkXIyJJEGWC2U4wJtJsYriu1X3MLBXIBva0c2x7bVYAvwuXfw+c3O13kETuHkxRzuvc+EuzIUOMRefPYOPuGp5ct6uHoxMR6ViUCeY1YKaZFZpZGsGg/bIW+ywDrgqXLwee86Ba4zJgYTjLrBCYCazooM0/AOeFy+cCGyN6X72iuchlZ2aQtXTJyROYMSaLHzy1gQbNKBORXhZZggnHVBYBTwJvAw+5+zozu9nMLg13uxfINbMS4AZgcXjsOuAhYD3wBHCduze21WbY1veAT5nZWuD/Al+K6r31htLK5qdYdq0HA5AyxPjGhcdRGqvlkdcreio0EZGEdG70uJPc/THgsRbrbopbrgOuaOPYW4BbEmkzXL8P+Hg3Q+4zyqrCKcpjup5gAC6aPZZTJ4/itqc3sWBOAcOGpvREeCIiHRpIg/wDSmllUORy/Mhh3WrHzPjW/OPZtb9ONcpEpFcpwfRRZVWJF7nsyJnTcjl3Vj53/aWUfQfreyA6EZGOKcH0UWWx2m4N8Le0+OLjOVB3hB89s6nH2hQRaY8STB9Ud6SRbXsPdmuAv6UTxo/k7z8whQde3cI7u/b3WLsiIm1RgumDtuw5iHeyyGUibrhgFiOGpfKdZesJZoOLiERHCaYPKu1ikcuOjB6extcvPI5Xyvbw+Fu6+VJEoqUE0weVdbHIZSI+O3cyJ4wfyXcfXU+tHkomIhFSgumDSmO1jM/ufJHLRKQMMf5zwWx2VNfxw6f6dbEDEenjlGD6oLJYTcKPSe6K4qk5/MOZU7j/b+W8sXVvZOcRkcFNCaaPaS5y2dPjLy19c/5xjBs5jMWPrKW+QXXKRKTnKcH0MbEDQZHLaRGMv8QbMWwo373sRDbsPsDdL5RGei4RGZyUYPqY0lhQ5LK7NcgSMe+EsVxy8nh+8twm1u2ojvx8IjK4KMH0Mc1TlHvyJsv23LzgREZlpvG1B1dTd6SxV84pIoODEkwfUxbrmSKXicoZnsYPrjiFjbtr+K8nNvTKOUVkcFCC6WPKqmqY1kNFLhN17qx8rvrgFO57uZwXN8V67bwiMrApwfQxpRFPUW7L4otPYMaYLL7x2zfZU3O4188vIgOPEkwfUnekkYq9hyKfotyajLQUfrxwDnsPHuGrD66msUm1ykSke5Rg+pDNe2pxJyk9GIDZE7L5zqWzeXFTFbc/q7L+ItI9SjB9SFnzFOUk9GCaLTxjEp88rYDbn9vECxs1HiMiXRdpgjGz+Wa2wcxKzGxxK9vTzezBcPtyM5sat+3GcP0GM7uoozbN7OdmVm5mq8OvOVG+tyiUVkZX5DJRZsYtl53ErDEj+OrSN9i+71DSYhGR/i2yBGNmKcCdwMVAEXClmRW12O1qYK+7zwBuA24Njy0CFgKzgfnAXWaWkkCb/+Luc8Kv1VG9t6iUVUVX5LIzMtJS+OnnTuNIo/OlJStVdVlEuiTKHsxcoMTdy9y9HlgKLGixzwJgSbj8MDDPzCxcv9TdD7t7OVAStpdIm/1WWawmqZfH4k3Lz+Innz2VDbv287UHV9OkQX8R6aQoE0wBsC3udUW4rtV93L0BqAZy2zm2ozZvMbM1ZnabmaW3FpSZXWNmK81sZSzWd8YY3J3SWG3SBvhbc95xY/i3jxfx1Prd/OAp3YQpIp0zkAb5bwSOB84AcoBvtbaTu9/j7sXuXpyfn9+b8bUrduAwNYcb+kwPptkXzprKZz8wmbv+UsojqyqSHY6I9CNRJpjtwKS41xPDda3uY2apQDawp51j22zT3Xd64DBwP8HltH6j5GgNsr7Tg4Fg0P87l87mrBm5fOuRNfxlQ2WyQxKRfiLKBPMaMNPMCs0sjWDQflmLfZYBV4XLlwPPubuH6xeGs8wKgZnAivbaNLPx4b8GXAa8FeF763HNU5R7q8hlZwxNGcLdnzudWWNHcO0vX9dDykQkIZElmHBMZRHwJPA28JC7rzOzm83s0nC3e4FcMysBbgAWh8euAx4C1gNPANe5e2NbbYZt/crM1gJrgTzgu1G9tyiUxWrJGJrSa0UuO2vEsKH8/ItnkD8inS/+/DVKwinVIiJtsaDDMDgVFxf7ypUrkx0GAFfdt4LYgcM8dv2Hkx1Ku7bsqeVTP32FtBTjt9d+iIJRGckOSUR6mZmtcvfijvYbSIP8/VpZVU2vPGSsu6bkDufnXziDA4cbuPKeV9lZrRsxRaR1SjB9QHORy6gfk9xTTizI5hdfnMve2noW3vMqu6rrkh2SiPRBSjB9QLKLXHbFqZNHs+TqueypqefK/3mV3fuVZETkWAklGDM728y+EC7nhzO7pIeUVia/yGVXnDZ5NEu+eAaV++u48p5XVbdMRI7RYYIxs/8guGnxxnDVUOCXUQY12JT10XtgEnH6lByWfHEusQOHueKnf6M0ptllIhJIpAfzd8ClQC2Au+8ARkQZ1GBTVlXLhOxhZKYlt8hlVxVPzeE315xJfWMTV9z9Cm9tr052SCLSBySSYOrDmx8dwMz635/ZfVzwmOT+dXmspRMLsvntP3+IjKEpLLznVV4p3ZPskEQkyRJJMA+Z2X8Do8zsH4FngJ9FG9bg4e6UxWqZ3g8vj7VUmDech6/9IOOyh3HVfSv44+qWlYFEZDDpMMG4+w8ISuk/AhwH3OTut0cd2GBRGRa57O89mGbjszP47T99kDmTR3H90tX8+JlNDOabeUUGs0QG+W9196fd/V/c/Rvu/rSZ3dobwQ0Gpf14gL8to4en8cDVc/nkaQXc9sxGvv7QmxxuaEx2WCLSyxK5RHZBK+su7ulABqvmIpf9bYpyR9JTU/jhFafwjQtn8bs3tvO5ny2n8oDulREZTNpMMGZ2bVg88rjwIV7NX+XAmt4LcWArjdWQMTSFcX20yGV3mBmLzp/JT648lbXbq/nET15i1RZVYhYZLNrrwfwa+ARBOfxPxH2d7u6f64XYBoWy8CmWQ4ZYskOJzCdOmcDvv3wW6akpLLznFR54dYvGZUQGgTYTjLtXu/tmd7/S3bcAhwimKmeZ2eRei3CAGwhTlBNxwviR/GnR2Zw1I49//8Nb/MvDazhUr3EZkYEskUH+T5jZJqAceAHYDDwecVyDQt2RRrbv6z9FLrsrO3Mo9111Bl+ZN5OHV1Vw6R0v8c6u/ckOS0Qiksgg/3eBM4GN7l4IzANejTSqQaK8Kihy2R/K9PeUIUOMGy6YFVRjPniES+94mV+8slmXzEQGoEQSzBF33wMMMbMh7v480OGDZqRjRx+TPEh6MPHOmZXPE1/9MGdNz+WmP67jH3+xindr65Mdloj0oEQSzD4zywL+SvBY4h8T1iWT7unPRS57Ql5WOvd9/gxuuqSIv26McdGP/soz63cnOywR6SGJJJgFwEHga8ATQCnBbDLpptJYTb8uctkTzIwvnl3IH647i9zhaXzpFyu54cHVVB88kuzQRKSbEikVU+vuTe7e4O5LgDuA+Yk0bmbzzWyDmZWY2eJWtqeb2YPh9uVmNjVu243h+g1mdlEn2rzdzPpFzfiyqtpBNf7SnqIJI1m26Gy+Mm8my97cwQW3vaDejEg/196NliPDX/J3mNmFFlgElAGf7qhhM0sB7iS4678IuNLMilrsdjWw191nALcBt4bHFgELgdkEyewuM0vpqE0zKwZGJ/jek8rdKa2sGZTjL21JSx3CDRfM4g/XnUVO2Ju5fukbxA4cTnZoItIF7fVgHiAobrkW+BLwPHAFcJm7L0ig7blAibuXuXs9sJTgclu8BcCScPlhYJ6ZWbh+qbsfdvdyoCRsr802w+TzfeCbCcSWdJUHDlNb3zgo7oHprBMLslm26GyunzeTx9fu4vwf/oUHXtlMY5Nmmon0J+0lmGnu/nl3/2/gSoIew0XuvjrBtguAbXGvK8J1re7j7g1ANZDbzrHttbkIWObuOxOML6mai1wOtBpkPSUtdQhfu2AWj3/1w5w8MZt//+M6/u6ul1lTsS/ZoYlIgtpLMEdHWd29Eahw9z5ZrdDMJhD0rn6SwL7XmNlKM1sZi8WiD64Npc1TlAfpDLJETc/P4pdXf4AfL5zDzuo6Ftz5Mv/+h7c0pVmkH2gvwZxiZvvDrwPAyc3LZpbI7dfbgUlxryeG61rdx8xSgWxgTzvHtrX+VGAGUGJmm4FMMytpLSh3v8fdi929OD8/P4G3EY2yWA2ZaQOzyGVPMzMWzCng2a+fy/86cwq/Wr6Fc7//PD97sYz6hqZkhycibWivFlmKu48Mv0a4e2rc8sgE2n4NmGlmhWaWRjBov6zFPsuAq8Lly4HnwsczLwMWhrPMCoGZwIq22nT3P7v7OHef6u5TgYPhxIE+qzRWS2HewC5y2dNGDhvKdxacyBNfPYfTJo/mu39+mwtue4En3tqlSgAifVAi98F0STimsgh4EngbeMjd15nZzWZ2abjbvUBu2Nu4AVgcHrsOeAhYT3DvzXXu3thWm1G9hyiVDZIil1GYNXYES744l59/4QzSUobwz79cxWfueZXXt+pRACJ9iQ3mv/yKi4t95cqVvX7euiONnHDTE1w/byZf/eisXj//QNLQ2MTS17Zx29Mb2VNbz7zjx3DDhbOYPSE72aGJDFhmtsrdOywZFlkPRtrWXORSPZjuS00ZwufOnMJfv3ke/3LRcby2+V0+fvtLXPer1ymp7Bf324oMWIO3RkkSvfeYZM0g6ynD01O57rwZfO7MKfzsxTLue6mcx9/ayWWnFrDovBlK5iJJ0GGCCWeQtbyOVg2sBL7u7mVRBDaQNd8DU6i7+HtcdsZQvn7hcXz+Q1O5+4VSfvHKFn7/xnY+duJ4rv3IdE4s0KUzkd6SSA/mRwQ3NP4aMIKZW9OB14H7gI9EFdxAVRaroWBUxqAuchm13Kx0/vXjRVxzznTuf7mcB17Zwp/X7uQjx+Vz3XkzOGNqTrJDFBnwEhmDudTd/9vdD7j7fne/h+CO/gfpJ3W/+prSWK1usOwl+SPS+eb843lp8fn8y0XHsbaimivufoVP3/0Kz6zfTZPKz4hEJpEEc9DMPm1mQ8KvTwPNd/Trf2cnuXswRVmXx3pVdsZQrjtvBi9963y+/YkiKvYe5Eu/WMn5P/wLP3+5nJrDDckOUWTASSTB/D3wD0AlsDtc/pyZZRDckyKdsHt/UORSZfqTIyMthc+fVcgL3zyPOz57KjnD0/j2n9bzwf/vWf7z0fVse/dgskMUGTA6HAQIB/HbesDYSz0bzsB39CmWeUowyTQ0ZQiXnDyBS06ewBtb93L/y5tZ8rfN3P9yOR89YSx/f+YUPjwjT5UWRLohkVlk+cA/AlPj93f3L0YX1sBVWhVOUR6jS2R9xamTR3Pq5NHc+LHjeeCVLSx9bRtPrd/NpJwMFp4xmU8XTyJ/RHqywxTpdxKZxvRH4EXgGaAx2nAGvtJKFbnsq8ZnZ/DN+cdz/Udn8uS63fx6+Ra+/+QGbnt6IxfOHstn507hQ9Nz1asRSVAiCSbT3b8VeSSDRFlVMIMseK6a9EXpqSlcesoELj1lAqWxGn6zfCsPv17BY2t3MSkng0+eOpFPnTaRybmZyQ5VpE9LZJD/UTP7WOSRDBLBY5I1/tJfTM/P4t8uKeLVG+fx44VzmJIznNuf28Q533+eK+7+G0tXbGV/3ZGOGxIZhDosdhneyT8cOEzwEDIDPMGS/X1abxe7VJHLgWHHvkP8YfV2HllVQWmslvTUIVw4exyfPK2As2fkMTRFJf5kYEu02GUis8hG9ExI0lzkUo9J7t8mjMrgyx+ZwbXnTufNimoeWVXBsjd38Kc3dzA6cyjzTxzHJSdP4AOFOaQq2cgg1maCMbPj3f0dMzutte3u/np0YQ1MzTXIdBf/wGBmzJk0ijmTRvFvl5zAXzdW8eiaHSxbvYPfrNhGXlYaF584nktOHs8ZU3M0OUAGnfZ6MDcA1wA/bGWbA+dHEtEA1lxFWWMwA096agoXFI3lgqKx1B1p5Pl3Knl0zU5+u2obD7y6hbEj05k/exwXzh7H3MIcXUaTQaHNBOPu14T/ntd74QxspWGRy4y0lGSHIhEaNjSFi08az8Unjaf2cAPPvlPJo2/u4MGV21jyyhZGDktl3gljubBoLOfMymd4uoqeysCU0E+2mX2I999o+YuIYhqwylTkctAZnp56dMrzofpGXtwU46n1u3nm7d38/o3tpKUO4cMz8rhw9ljmnTCWvCzd0CkDRyJ38j9AUJ5/Ne/daOmAEkwnNBe5vKJ4UrJDkSTJSEvhwvAyWUNjE69t3stT63fx1LrdPPtOJWZrOakgm48cN4aPHJfPKRNHkaJxG+nHEunBFANF3tF85laY2Xzgx0AK8DN3/16L7ekEiep0YA/wGXffHG67EbiaIKl9xd2fbK9NM7s3jNWAjcDn3b3PPDO3ucilejACwaOePzg9lw9Oz+WmS4pYt2M/z79TyfMbKrnjuU3c/uwmRmcO5ZxZ+Zx33BjOmZVPzvC0ZIct0imJJJi3gHHAzs40bGYpwJ3ABQQPLHvNzJa5+/q43a4G9rr7DDNbCNwKfMbMiggebDYbmAA8Y2bNN4601ebX3H1/eO7/R1Dp+ZiElkzNRS41RVlaMjNOLMjmxIJs/ve8meytrefFkir+8k4lL2yM8cfVOzCDUyaO4txZ+Zw1I485k0aRlqqJAtK3JZJg8oD1ZraC4GZLANz90g6OmwuUND9S2cyWAguA+ASzAPh2uPwwcIcFNVQWAEvd/TBQbmYlYXu01WZccjEggz72rBpNUZZEjR6ednTcpqnJWbu9mr9siPH8hkp+8twmfvzsJjLTUphbmMNZ0/P40IxcThg3UtOgpc9JJMF8u4ttFwDb4l5XAB9oax93bzCzaiA3XP9qi2MLwuU22zSz+4GPESSxr3cx7kiUxmpV5FI6bcgQ45RJozhl0iiu/+hMqg8d4dWyPbxcUsXLJVXcsuFtAHKGp/HB6bmcNT2Ps2bkMjknU/XuJOnaTTDhZa5v95epyu7+hTDmnwCfAe5vuY+ZXUNwfw+TJ0/utdhKYzUqcindlp0xlItmj+Oi2eMA2FVdFySb0ir+VrKHP68JrmSPHZnO3MJc5hbmMHdqDjPHZKmHI72u3QTj7o1m1mRm2e5e3cm2twPxU6Ymhuta26fCzFKBbILB/vaObbfNMOalwDdpJcG4+z3APRDUIuvcW+q6slgtp08Z3Vunk0FiXPYwPnX6RD51+kTcndJYLa+W7WFF+busKH+XP725A4BRmUM5Y2oOHyjMYW5hDkXjR6qMjUQukUtkNcBaM3saqG1e6e5f6eC414CZZlZIkAQWAp9tsc8y4CrgFeBy4Dl3dzNbBvw6HKyfAMwEVhDMEHtfm+G4y3R3LwmXLwXeSeC99YpD9Y3sqD7Ep/M1RVmiY2bMGJPFjDFZfO7MKbg7FXsPsbz8XVaUB0nn6fW7ARielsJpU0Zz+pTgYWtzJo0iO2Nokt+BDDSJJJjfhV+dEo6pLAKeJJhSfJ+7rzOzm4GV7r4MuBd4IBzEf5cgYRDu9xDBWEoDcJ27NwK00eYQYImZjSRIQm8C13Y25qg0F7nUAL/0JjNjUk4mk3Iyufz0iQBU7q9jxeZ3j/ZwfvzsJppvQJgxJovTJo8Kn/A5ipljRug+HOmWDsv1D2S9Va7/0TU7WPTrN3jsKx+maEK/f8qBDCAH6o6wpqKaN7bu5fWt+3hj6172Hgyeb5OVnsopk7I5LezhnFSQzRhNUhF6sFy/mc0E/i9QBBz96XL3ad2KcBAprQyuLBbmqQcjfcuIYUM5a0YeZ83IA4KKE5v3HOSNrXt5Y+s+Xt+6l7v+UkpjU/CH6NiR6ZxUECSbkycG9+7kj1B5G2ldIpfI7gf+A7gNOA/4Aok9CVNCZVUqcin9g5lRmDecwrzhfPK04LLawfoG1u3Yz5qKat7aXs2ain08+87uo5fWxmcPOybhnFSQTa5qqgmJJZgMd3/WzMzdtwDfNrNVwE0RxzZgNE9RFumPMtNSOWNqDmdMzTm6ruZwA+u2V7N2e/XRxPNUOIEAoGBUBieMH8EJ40ce/ZqSk6mp0oNMIgnmcDiIvikcYN8OqN5Jgtyd8lgtxcU5He8s0k9kpafygWm5fGBa7tF1++uOsG77ftZu38db2/fz9s79PL8hdvTyWmZaCseNey/pFI0fwXHjRpKlxxUMWIl8Z68HMoGvAP9JcJnsqiiDGkiai1xOVw9GBriRw4YeLeDZrO5II5t21/D2zv2s3xkknUff3MGvl289us+U3EyODxPP8eNGMHPsCKbkZOo+nQGgwwTj7q8BmFmTu38h+pAGlvdqkKnTJ4PPsKEpnDQxm5MmZh9d5+7sqK7j7R1Bwnl7137e2XmAp9a/N66TljKEafnDmTEmi1ljRzBzTFaQeHIz9TTQfiSRWWQfJLhfJQuYbGanAP/k7l+OOriBQFWURY5lZhSMyqBgVAYfLRp7dP3B+gZKKmvYtLuGjZUHKNldw5sV+3h0zXuF3IemGNPyspgxNotZY0Ywc2wWs8ZmMSV3uBJPH5TIJbIfARcR3HWPu79pZudEGtUAUhqrZXhaCmNHalaNSHsy01I5eeIoTp446pj1B+sbKK2sZVMrHjLXAAATeUlEQVTlATburqGk8gBrK6p5bO3Ooz2elCHG5JxMpuUNZ1r+cKblZ1EYLudnpasGYJIkNLrm7ttafIMa29pXjlUaq6FQRS5FuiwzLfV9l9kgKMFUGqth4+4DlMZqKK+qpSxWy0slVRxuaDq634j0VArzh4fJJ4tp+cE07Gl5Wbp1IGKJJJhtZvYhwM1sKMGg/9vRhjVwlMVqKZ6qIpciPS0jLeXog9riNTU52/cdoqyqlvJYDWVh4llR/i5/WL3jmH0nZA9jcm4mU3KGB//mZjI1N1geOUy12borkQTzzwSPKC4gmKL8FKDxlwQcqm9k+75DfDpPRS5FesuQIe/VYDt3Vv4x2w7WN7C56iBlVTWUxWopr6ply55ann1nN1U19cfsOzpzKJNzhzMlJ5OpuZnBcm4mU3IyyR+hy26JSGQWWRXw9/HrzOyrBGMz0o7yqqBEzPQxmqIs0hdkpqVSNGFkqzUBaw43sGVPLVv3HGTLuwfZsucgW9+t5fWte3l0zQ6a4so2ZgxNYXJO0OOZkpvJxNGZTBydwcTRmRSMztC9PaGufgo3oATToaNTlPM0g0ykr8tKT2X2hGxmT8h+37b6hiYq9gaJZ+ue95JPeVUtL2yMHTPmA8HzdyaOzmDiqCDhNCefiaMzKBidMWguv3U1wahvmICymIpcigwEaalDwgkC7/9j0d2pqqmnYu9BKvYeomLvIbbvC5ZLYjW8sDHGoSPHzosaOSz1fb2eglEZTBg1jPHZGeQOTxsQZXW6mmAGb43/TiiNqcilyEBnZuSPSCd/RDqnTn7/hB53593a+vcln4q9h9i8J5j1drD+2ASUljKEcdnDGJc9jAnZwxg/KoPx2UHyCf4dRs7wtD4/DtRmgjGzA7SeSAzIiCyiAaSsSkUuRQY7MyM3K53crHROmTTqfdvdnX0Hj1Cx9xA7qw+xs7qOHdWH2FVdx859dazcspfda3dypPHYX8fpqUMYfzQJZTB+VHwCymBc9jBGZw5NahJqM8G4+4jeDGSgcXfKYrV8WkUuRaQdZsbo4WmMHp72vnt9mjU1OVW1h9m5r46d1YfYsa+OXfvr2LEvSEjLy99l1/66o4VFm6WlDmHsyHTGjRzG2JHDGDcySEhjRg7j3Fn5kT8mW1MdIrJrfx0HVeRSRHrAkCHGmBHDGDNiWKu9IIDGJid24DA7qg+xM0xAu8OvXdV1vLW9mmfe3k3dkWBCwnNfP1cJpr9qHuBXDTIR6Q0pQ+zouA2TW9/H3dl/qIFd++uYlJMZeUxKMBFRFWUR6WvMjOzMoWRn9s406UjLj5rZfDPbYGYlZra4le3pZvZguH25mU2N23ZjuH6DmV3UUZtm9qtw/Vtmdl9Y1iZpylTkUkQGucgSjJmlAHcCFwNFwJVmVtRit6uBve4+A7gNuDU8tghYCMwG5gN3mVlKB23+CjgeOIlgltuXonpviQgek5zV56cRiohEJcoezFygxN3L3L0eWAosaLHPAmBJuPwwMM+C38gLgKXuftjdy4GSsL0223T3xzwErAAmRvjeOlQWq9UUZREZ1KJMMAXAtrjXFeG6Vvdx9wagGsht59gO2wwvjf0D8ERrQZnZNWa20sxWxmKxTr6lxDQXudQAv4gMZgPxEXB3AX919xdb2+ju97h7sbsX5+fnt7ZLt5VVNQ/wqwcjIoNXlLPItgPxdeonhuta26fCzFKBbGBPB8e22aaZ/QeQD/xTD8TfZc1TlFXkUkQGsyh7MK8BM82s0MzSCAbtl7XYZxlwVbh8OfBcOIayDFgYzjIrBGYSjKu02aaZfYng0c5XunsTSVQaq8FMRS5FZHCLrAfj7g1mtgh4EkgB7nP3dWZ2M7DS3ZcB9wIPmFkJ8C5BwiDc7yFgPdAAXOfujQCttRme8m5gC/BKOHPrd+5+c1Tvrz1lsVomZKvIpYgMbpHeaOnujwGPtVh3U9xyHXBFG8feAtySSJvh+j5z02hZVQ3Tx+jymIgMbgNxkD+pmotcTtPlMREZ5JRgetjRIpfqwYjIIKcE08NKK8Mil+rBiMggpwTTw967B0Y9GBEZ3JRgepiKXIqIBJRgepiKXIqIBJRgelhZrFZPsRQRQQmmRx2sb2D7vkMafxERQQmmR5VXhTXI1IMREVGC6UmlYZFLlekXEVGC6VFlKnIpInKUEkwPKovVUjAqg2FDVeRSREQJpgc1T1EWERElmB7T1OSaoiwiEkcJpofs2l/HoSON6sGIiISUYHpI82OSVeRSRCSgBNNDmotcqky/iEhACaaHlFbWMDwthTEjVORSRASUYHpMWVUt08eoyKWISLNIE4yZzTezDWZWYmaLW9mebmYPhtuXm9nUuG03hus3mNlFHbVpZovCdW5meVG+r9aUVtboMckiInEiSzBmlgLcCVwMFAFXmllRi92uBva6+wzgNuDW8NgiYCEwG5gP3GVmKR20+TLwUWBLVO+pLQfrG9hRXacZZCIicaLswcwFSty9zN3rgaXAghb7LACWhMsPA/MsuMa0AFjq7ofdvRwoCdtrs013f8PdN0f4ftpUphpkIiLvE2WCKQC2xb2uCNe1uo+7NwDVQG47xybSZq8rUxVlEZH3GXSD/GZ2jZmtNLOVsVisR9pUkUsRkfeLMsFsBybFvZ4Yrmt1HzNLBbKBPe0cm0ib7XL3e9y92N2L8/PzO3Nom0pV5FJE5H2iTDCvATPNrNDM0ggG7Ze12GcZcFW4fDnwnLt7uH5hOMusEJgJrEiwzV5XFqvR+IuISAuRJZhwTGUR8CTwNvCQu68zs5vN7NJwt3uBXDMrAW4AFofHrgMeAtYDTwDXuXtjW20CmNlXzKyCoFezxsx+FtV7i9dc5FLjLyIix0qNsnF3fwx4rMW6m+KW64Ar2jj2FuCWRNoM198O3N7NkDtNRS5FRFo36Ab5e9p7U5TVgxERiacE002lsbDIpXowIiLHUILpprJYDVnpqSpyKSLSghJMN5WGA/wqcikiciwlmG4qi6nIpYhIa5RguqG5yKXGX0RE3k8JphuaZ5BpirKIyPspwXRDc5HL6WN0iUxEpCUlmG4orQyKXE7NVYIREWlJCaYbyqpqmThaRS5FRFqjBNMNwWOSNf4iItIaJZguampyyqtU5FJEpC1KMF20MyxyqSnKIiKtU4LporKwBpl6MCIirVOC6aLme2BmqAcjItIqJZguKg2LXOaryKWISKuUYLqoLFbLdBW5FBFpkxJMF5XGalQiRkSkHUowXXCwvoGd1XWqoiwi0o5IE4yZzTezDWZWYmaLW9mebmYPhtuXm9nUuG03hus3mNlFHbVpZoVhGyVhm2lRva+jj0keox6MiEhbIkswZpYC3AlcDBQBV5pZUYvdrgb2uvsM4Dbg1vDYImAhMBuYD9xlZikdtHkrcFvY1t6w7UiUaoqyiEiHouzBzAVK3L3M3euBpcCCFvssAJaEyw8D8ywYNV8ALHX3w+5eDpSE7bXaZnjM+WEbhG1eFtUbK4vVqsiliEgHokwwBcC2uNcV4bpW93H3BqAayG3n2LbW5wL7wjbaOlePKY3VqMiliEgHUpMdQG8zs2uAawAmT57cpTZOGD+SiaMzezIsEZEBJ8oEsx2YFPd6YriutX0qzCwVyAb2dHBsa+v3AKPMLDXsxbR2LgDc/R7gHoDi4mLv/NuC686b0ZXDREQGlSgvkb0GzAxnd6URDNova7HPMuCqcPly4Dl393D9wnCWWSEwE1jRVpvhMc+HbRC2+ccI35uIiHQgsh6MuzeY2SLgSSAFuM/d15nZzcBKd18G3As8YGYlwLsECYNwv4eA9UADcJ27NwK01mZ4ym8BS83su8AbYdsiIpIkFvzxPzgVFxf7ypUrkx2GiEi/Ymar3L24o/10J7+IiERCCUZERCKhBCMiIpFQghERkUgowYiISCQG9SwyM4sBW7p4eB5Q1YPh9BTF1TmKq3MUV+cM1LimuHt+RzsN6gTTHWa2MpFper1NcXWO4uocxdU5gz0uXSITEZFIKMGIiEgklGC67p5kB9AGxdU5iqtzFFfnDOq4NAYjIiKRUA9GREQioQTTBWY238w2mFmJmS3uhfNtNrO1ZrbazFaG63LM7Gkz2xT+Ozpcb2Z2exjbGjM7La6dq8L9N5nZVW2dr4NY7jOzSjN7K25dj8ViZqeH77UkPNa6Ede3zWx7+LmtNrOPxW27MTzHBjO7KG59q9/b8BERy8P1D4aPi+gopklm9ryZrTezdWZ2fV/4vNqJK9mf1zAzW2Fmb4Zxfae9tix4nMeD4frlZja1q/F2Ma6fm1l53Oc1J1zfaz/34bEpZvaGmT3aFz6vY7i7vjrxRfCYgFJgGpAGvAkURXzOzUBei3X/BSwOlxcDt4bLHwMeBww4E1gers8BysJ/R4fLo7sQyznAacBbUcRC8NyfM8NjHgcu7kZc3wa+0cq+ReH3LR0oDL+fKe19b4GHgIXh8t3AtQnENB44LVweAWwMz53Uz6uduJL9eRmQFS4PBZaH763VtoAvA3eHywuBB7sabxfj+jlweSv799rPfXjsDcCvgUfb++x76/OK/1IPpvPmAiXuXubu9cBSYEES4lgALAmXlwCXxa3/hQdeJXjS53jgIuBpd3/X3fcCTwPzO3tSd/8rwbN7ejyWcNtId3/Vg5/8X8S11ZW42rIAWOruh929HCgh+L62+r0N/5o8H3i4lffYXkw73f31cPkA8DZQQJI/r3biaktvfV7u7jXhy6Hhl7fTVvzn+DAwLzx3p+LtRlxt6bWfezObCHwc+Fn4ur3Pvlc+r3hKMJ1XAGyLe11B+/85e4IDT5nZKjO7Jlw31t13hsu7gLEdxBdl3D0VS0G43JMxLgovU9xn4aWoLsSVC+zz4HHcXYorvBxxKsFfv33m82oRFyT58wov96wGKgl+AZe209bR84fbq8Nz9/j/gZZxuXvz53VL+HndZmbpLeNK8Pzd+T7+CPgm0BS+bu+z77XPq5kSTP9wtrufBlwMXGdm58RvDP/q6RPTAftSLMBPgenAHGAn8MNkBGFmWcAjwFfdfX/8tmR+Xq3ElfTPy90b3X0OMJHgL+jjezuG1rSMy8xOBG4kiO8Mgste3+rNmMzsEqDS3Vf15nk7Qwmm87YDk+JeTwzXRcbdt4f/VgK/J/iPtzvsWhP+W9lBfFHG3VOxbA+XeyRGd98d/mJoAv6H4HPrSlx7CC5zpLZY3yEzG0rwS/xX7v67cHXSP6/W4uoLn1czd98HPA98sJ22jp4/3J4dnjuy/wNxcc0PLzW6ux8G7qfrn1dXv49nAZea2WaCy1fnAz+mD31ekQ1MD9QvIJVgcK6Q9wa+Zkd4vuHAiLjlvxGMnXyfYweK/ytc/jjHDjCuCNfnAOUEg4ujw+WcLsY0lWMH03ssFt4/2PmxbsQ1Pm75awTXmQFmc+ygZhnBgGab31vgtxw7cPrlBOIxguvpP2qxPqmfVztxJfvzygdGhcsZwIvAJW21BVzHsYPWD3U13i7GNT7u8/wR8L1k/NyHx3+E9wb5k/p5HRNXV37BDPYvglkiGwmuD/9rxOeaFn5j3wTWNZ+P4Nrps8Am4Jm4H1QD7gxjWwsUx7X1RYIBvBLgC12M5zcEl0+OEFyTvbonYwGKgbfCY+4gvBm4i3E9EJ53DbCMY3+B/mt4jg3Ezdhp63sbfh9WhPH+FkhPIKazCS5/rQFWh18fS/bn1U5cyf68TgbeCM//FnBTe20Bw8LXJeH2aV2Nt4txPRd+Xm8Bv+S9mWa99nMfd/xHeC/BJPXziv/SnfwiIhIJjcGIiEgklGBERCQSSjAiIhIJJRgREYmEEoyIiERCCUakk8wsN66C7i47tgJxh1WDwzbuN7PjOnHO8Wb2WFjRd72ZLQvXTzOzhV19LyJR0jRlkW4ws28DNe7+gxbrjeD/V1OrB3b+PPcCr7v7neHrk919jZl9FFjk7gkVRxTpTerBiPQQM5sR9i5+RXBT7Hgzu8fMVlrwHJGb4vZ9yczmmFmqme0zs++FvZNXzGxMK82PJ64goruvCRe/B5wX9p6+Erb3/yx4fskaM/tSeL6PWvAMmMfD53vcGSZBkcgowYj0rOOB29y9yIMacovdvRg4BbjAzIpaOSYbeMHdTwFeIbjbu6U7gCVm9pyZ/Z/mWmYEpWaed/c57n47cA1BAcS5BEUYrzOzyeG+HwCuJXj+xwkk5zETMogowYj0rFJ3Xxn3+kozex14neCXemsJ5pC7Px4uryKoqXYMd3+MoNLxvWEbb5hZbittXQh8ISwtvxwYBcwMt73q7pvdvZGgOOLZnX1zIp2R2vEuItIJtc0LZjYTuB6Y6+77zOyXBPWgWqqPW26kjf+X7r4H+BXwKzN7giBB1LbYzQiKGz57zMpgrKblgKsGYCVS6sGIRGckcADYH/dEwy4xs3lmlhEujySocLs1bH9E3K5PAl9uLtduZsc1HwecaWaTzSwF+DTwUlfjEUmEejAi0XkdWA+8A2wBXu5GW2cAd5jZEYI/DH/q7m+E06JTzOxNgstndwKTgdXhGH4l7421rCAo3z6doIrzsm7EI9IhTVMWGQQ0nVmSQZfIREQkEurBiIhIJNSDERGRSCjBiIhIJJRgREQkEkowIiISCSUYERGJhBKMiIhE4v8HHkxC8Rs2bTIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_model = 512\n",
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "#plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.plot(temp_learning_rate_schedule(torch.arange(0, 40000).to(dtype=torch.float)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = vocab_size + 2\n",
    "target_vocab_size = vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5841, 1.3897])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamurataito/opt/anaconda3/envs/transformer_env/lib/python3.7/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# Testing nn.CrossEntropyLoss()\n",
    "y_true = [1, 2]\n",
    "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
    "\n",
    "loss = nn.CrossEntropyLoss(reduce=False)\n",
    "input = torch.tensor(y_pred)\n",
    "target = torch.tensor(y_true)\n",
    "output = loss(input, target)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = nn.CrossEntropyLoss(reduce=False)\n",
    "\n",
    "def loss_function(pred, real):\n",
    "    mask = torch.logical_not(torch.eq(real, 0))\n",
    "    loss_ = loss_object(pred.to(dtype=torch.float), real.to(dtype=torch.long))\n",
    "    loss_ *= mask\n",
    "  \n",
    "    return torch.sum(loss_)/torch.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9869)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing loss_function()\n",
    "loss_function(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inp, tar, batch_number):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "  \n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "    predictions, _ = model(inp, tar_inp, True, enc_padding_mask, combined_mask, dec_padding_mask)\n",
    "    \n",
    "    loss = 0\n",
    "    for i in range(inp.shape[0]):\n",
    "        loss = loss + loss_function(predictions[i], tar_real[i])\n",
    "    \n",
    "    if(batch_number % 100 == 0):\n",
    "        print('loss: ' + str(loss.item()))\n",
    "  \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by \n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tar.shape[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = torch.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    #return enc_padding_mask.to(dtype=torch.long), combined_mask.to(dtype=torch.long), dec_padding_mask.to(dtype=torch.long)\n",
    "    \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "2\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "3\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "4\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "5\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "6\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "7\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "8\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "9\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "10\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "11\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "12\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "13\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "14\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "15\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "16\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "17\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "18\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "19\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "20\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "21\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "22\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "23\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "24\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "25\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "26\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "27\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "28\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "29\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "30\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "31\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "32\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "33\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "34\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "35\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "36\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "37\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "38\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "39\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "40\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "41\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "42\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "43\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "44\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "45\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "46\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "47\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "48\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "49\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "50\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "51\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "52\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "53\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "54\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "55\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "56\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "57\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "58\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "59\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "60\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "61\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "62\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "63\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "64\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "65\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "66\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "67\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "68\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "69\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "70\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "71\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "72\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "73\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "74\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "75\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "76\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "77\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "78\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "79\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "80\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "81\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "82\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "83\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "84\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "85\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "86\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "87\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "88\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "89\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "90\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "91\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "92\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "93\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "94\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "95\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "96\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "97\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "98\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "99\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "100\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "101\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "102\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "103\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "104\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "105\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "106\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "107\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "108\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "109\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "110\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "111\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "112\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "113\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "114\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "115\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "116\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "117\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "118\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "119\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "120\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "121\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "122\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "123\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "124\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "125\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "126\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "127\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "128\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "129\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "130\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "131\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "132\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "133\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "134\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "135\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "136\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "137\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "138\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "139\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "140\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "141\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "142\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "143\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "144\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "145\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "146\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "147\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "148\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "149\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "150\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "151\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "152\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "153\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "154\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "155\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "156\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "157\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "158\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "159\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "160\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "161\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "162\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "163\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "164\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "165\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "166\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "167\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "168\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "169\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "170\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "171\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "172\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "173\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "174\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "175\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "176\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "177\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "178\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "179\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "180\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "181\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "183\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "184\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "185\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "186\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "187\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "188\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "189\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "190\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "191\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "192\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "193\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "194\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "195\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "196\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "197\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "198\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "199\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "200\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "201\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "202\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "203\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "204\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "205\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "206\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "207\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "208\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "209\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "210\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "211\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "212\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "213\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "214\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "215\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "216\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "217\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "218\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "219\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "220\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "221\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "222\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "223\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "224\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "225\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "226\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "227\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "228\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "229\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "230\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "231\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "232\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "233\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "234\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "235\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "236\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "237\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "238\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "239\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "240\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "241\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "242\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "243\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "244\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "245\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "246\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "247\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "248\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "249\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "250\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "251\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "252\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "253\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "254\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "255\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "256\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "257\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "258\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "259\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "260\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "261\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "262\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "263\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "264\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "265\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "266\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "267\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "268\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "269\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "270\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "271\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "272\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "273\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "274\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "275\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "276\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "277\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "278\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "279\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "280\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "281\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "282\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "283\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "284\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "285\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "286\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "287\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "288\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "289\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "290\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "291\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "292\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "293\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "294\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "295\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "296\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "297\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "298\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "299\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "300\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "301\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "302\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "303\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "304\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "305\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "306\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "307\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "308\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "309\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "310\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "311\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "312\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "313\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "314\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "315\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "316\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "317\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "318\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "319\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "320\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "321\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "322\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "323\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "324\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "325\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "326\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "327\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "328\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "329\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "330\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "331\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "332\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "333\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "334\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "335\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "336\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "337\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "338\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "339\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "340\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "341\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "342\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "343\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "344\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "345\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "346\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "347\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "348\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "349\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "350\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "351\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "352\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "353\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "354\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "355\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "356\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "357\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "358\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "359\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "360\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "361\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "362\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "363\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "364\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "365\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "366\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "367\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "368\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "369\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "370\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "371\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "372\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "373\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "374\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "375\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "376\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "377\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "378\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "379\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "380\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "381\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "382\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "383\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "384\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "385\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "386\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "387\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "388\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "389\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "390\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "391\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "392\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "393\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "394\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "395\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "396\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "397\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "398\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "399\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "400\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "401\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "402\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "403\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "404\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "405\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "406\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "407\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "408\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "409\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "410\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "411\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "412\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "413\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "414\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "415\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "416\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "417\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "418\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "419\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "420\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "422\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "423\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "424\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "425\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "426\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "427\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "428\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "429\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "430\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "431\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "432\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "433\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "434\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "435\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "436\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "437\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "438\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "439\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "440\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "441\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "442\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "443\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "444\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "445\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "446\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "447\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "448\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "449\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "450\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "451\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "452\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "453\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "454\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "455\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "456\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "457\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "458\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "459\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "460\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "461\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "462\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "463\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "464\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "465\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "466\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "467\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "468\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "469\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "470\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "471\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "472\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "473\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "474\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "475\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "476\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "477\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "478\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "479\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "480\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "481\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "482\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "483\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "484\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "485\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "486\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "487\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "488\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "489\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "490\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "491\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "492\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "493\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "494\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "495\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "496\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "497\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "498\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "499\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "500\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "501\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "502\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "503\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "504\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "505\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "506\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "507\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "508\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "509\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "510\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "511\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "512\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "513\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "514\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "515\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "516\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "517\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "518\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "519\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "520\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "521\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "522\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "523\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "524\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "525\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "526\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "527\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "528\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "529\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "530\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "531\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "532\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "533\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "534\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "535\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "536\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "537\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "538\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "539\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "540\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "541\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "542\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "543\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "544\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "545\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "546\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "547\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "548\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "549\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "550\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "551\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "552\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "553\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "554\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "555\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "556\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "557\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "558\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "559\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "560\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "561\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "562\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "563\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "564\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "565\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "566\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "567\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "568\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "569\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "570\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "571\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "572\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "573\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "574\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "575\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "576\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "577\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "578\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "579\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "580\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "581\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "582\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "583\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "584\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "585\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "586\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "587\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "588\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "589\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "590\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "591\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "592\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "593\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "594\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "595\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "596\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "597\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "598\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "599\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "600\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "601\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "602\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "603\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "604\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "605\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "606\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "607\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "608\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "609\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "610\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "611\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "612\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "613\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "614\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "615\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "616\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "617\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "618\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "619\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "620\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "621\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "622\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "623\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "624\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "625\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "626\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "627\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "628\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "629\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "630\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "631\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "632\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "633\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "634\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "635\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "636\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "637\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "638\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "639\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "640\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "641\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "642\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "643\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "644\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "645\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "646\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "647\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "648\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "649\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "650\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "651\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "652\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "653\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "654\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "655\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "656\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "657\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "658\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "659\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "660\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "661\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "662\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "663\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "664\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "665\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "667\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "668\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "669\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "670\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "671\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "672\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "673\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "674\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "675\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "676\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "677\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "678\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "679\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "680\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "681\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "682\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "683\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "684\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "685\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "686\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "687\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "688\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "689\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "690\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "691\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "692\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "693\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "694\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "695\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "696\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "697\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "698\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "699\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "700\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "701\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "702\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "703\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "704\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "705\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "706\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "707\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "708\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "709\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "710\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "711\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "712\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "713\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "714\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "715\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "716\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "717\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "718\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "719\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "720\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "721\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "722\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "723\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "724\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "725\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "726\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "727\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "728\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "729\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "730\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "731\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "732\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "733\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "734\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "735\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "736\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "737\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "738\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "739\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "740\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "741\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "742\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "743\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "744\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "745\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "746\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "747\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "748\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "749\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "750\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "751\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "752\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "753\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "754\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "755\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "756\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "757\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "758\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "759\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "760\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "761\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "762\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "763\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "764\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "765\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "766\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "767\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "768\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "769\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "770\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "771\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "772\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "773\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "774\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "775\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "776\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "777\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "778\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "779\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "780\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "781\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "782\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "783\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "784\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "785\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "786\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "787\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "788\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "789\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "790\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "791\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "792\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "793\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "794\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "795\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "796\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "797\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "798\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "799\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "800\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "801\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "802\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "803\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "804\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "805\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "806\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "807\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "808\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "809\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "810\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "811\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "812\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "813\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "814\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "815\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "816\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "817\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "818\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "819\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "820\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "821\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "822\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "823\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "824\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "825\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "826\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "827\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "828\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "829\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "830\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "831\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "832\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "833\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "834\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "835\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "836\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "837\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "838\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "839\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "840\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "841\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "842\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "843\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "844\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "845\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "846\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "847\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "848\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "849\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "850\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "851\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "852\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "853\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "854\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "855\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "856\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "857\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "858\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "859\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "860\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "861\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "862\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "863\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "864\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "865\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "866\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "867\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "868\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "869\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "870\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "871\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "872\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "873\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "874\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "875\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "876\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "877\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "878\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "879\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "880\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "881\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "882\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "883\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "884\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "885\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "886\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "887\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "888\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "889\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "890\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "891\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "892\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "893\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "894\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "895\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "896\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "897\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "898\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "899\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "900\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "901\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "902\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "903\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "904\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "905\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "906\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "907\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "908\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "909\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "910\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "911\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "912\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "913\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "914\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "915\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "916\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "917\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "918\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "919\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "920\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "921\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "922\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "923\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "924\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "925\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "926\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "927\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "928\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "929\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "930\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "931\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "932\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "933\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "934\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "935\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "936\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "937\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "938\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "939\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "940\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "941\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "942\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "943\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "944\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "945\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "946\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "947\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "948\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "949\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "950\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "951\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "952\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "953\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "954\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "955\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "956\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "957\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "958\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "959\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "960\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "961\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "962\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "963\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "964\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "965\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "966\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "967\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "968\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "969\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "970\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "971\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "972\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "973\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "974\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "975\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "976\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "977\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "978\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "979\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "980\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "981\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "982\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "983\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "984\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "985\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "986\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "987\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "988\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "989\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "990\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "991\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "992\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "993\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "994\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "995\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "996\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "997\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "998\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "999\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1000\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1001\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1002\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1003\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1004\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1005\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1006\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1007\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1008\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1009\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1010\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1011\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1012\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1013\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1014\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1015\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1016\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1017\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1018\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1019\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1020\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1021\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1022\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1023\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1024\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1025\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1026\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1027\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1028\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1029\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1030\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1031\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1032\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1033\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1034\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1035\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1036\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1037\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1038\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1039\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1040\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1041\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1042\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1043\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1044\n",
      "torch.Size([64, 42]) torch.Size([64, 42])\n",
      "1045\n",
      "torch.Size([39, 42]) torch.Size([39, 42])\n"
     ]
    }
   ],
   "source": [
    "# Checking how the data loader works\n",
    "for i, data in enumerate(data_loader):\n",
    "    print(i)\n",
    "    print(data[0].shape, data[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\n",
      "batch 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-43e6599f7a89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0moutfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./torch_transformer_checkpoints/test_1_epoch\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-26d2696e30f7>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(inp, tar, batch_number)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/transformer_env/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/transformer_env/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)\n",
    "\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "optimizer = optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-9)\n",
    "EPOCHS = 20\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Epoch {}\".format(epoch))\n",
    "    print()\n",
    "    for i, data in enumerate(data_loader):\n",
    "        if(i%100 == 0):\n",
    "            print(\"batch {}\".format(i+1))\n",
    "        train_step(data[0], data[1], i+1)\n",
    "    \n",
    "    outfile = \"./torch_transformer_checkpoints/test_1_epoch\" + str(epoch + 1) + \".model\"\n",
    "    torch.save(model.state_dict(), outfile)\n",
    "    print(outfile + \" saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "s_qNSzzyaCbD"
   ],
   "name": "transformer.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
